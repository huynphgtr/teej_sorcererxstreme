[
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.4-ai-development/",
	"title": "AI Development",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.3-backend-development/",
	"title": "Backend Development",
	"tags": [],
	"description": "",
	"content": "Building and Automating with Serverless Backend (Serverless V4) This guide is a comprehensive document detailing the entire Backend development process for the SorcererXtreme AI project, from setting up the local development environment to completing the automated deployment workflow (CI/CD) on AWS.\n1. Context \u0026amp; Technical Challenges In the development of high-performance Serverless applications, we face several complex technical hurdles:\nFramework Transition: The transition from a traditional HTTP Framework like Express.js to the stateless environment of AWS Lambda requires using serverless-http and a change in source code structure. Database Management: Using a sophisticated ORM like Prisma on a Serverless platform necessitates techniques to optimize the deployment package size to under 250MB and requires downloading the correct Prisma Binary (rhel-openssl-3.0.x) for the Lambda Linux environment. Security: Ensuring that sensitive connection strings are never stored in the source code, but are securely managed using AWS SSM Parameter Store. 2. Core Value of the Constructed Architecture Our Backend architecture is designed to overcome these challenges, delivering key benefits:\nCost and Performance Optimization: Utilizing AWS Lambda and Serverless Framework V4 ensures you only pay for the time your code actually runs. Optimizing the Prisma package significantly reduces Cold Start time. Full Automation (CI/CD): Building the GitHub Actions workflow automates the entire development loop: Code -\u0026gt; Push -\u0026gt; Build -\u0026gt; Deploy, completely eliminating manual deployment steps and minimizing human error. Data Flexibility: Establishing a stable and secure connection to an external Database (NeonDB) demonstrates the capability for flexible integration in real-world projects. This guide will serve as a detailed, step-by-step map to help you master the entire process of modern Serverless Backend development.\nPrepare Set up environment Configure Serverless Framework Save secret key Automation CI/CD Connect microservices Set up email Development workflow "
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.2-frontend-development/",
	"title": "Frontend Development",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/repo-name/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Group Internship Details Project Information Field Detail Group name TEEJ_SorcererXStreme University FPT University - Ho Chi Minh Campus Internship company Amazon Web Services Vietnam Co., Ltd. Internship position FCJ Workforce Program Intern Internship duration From 08/09/2025 to 24/12/2025 Team Member Photo Role Full Name Major Contact Leader Tran Phuong Huyen Software Engineering tranphuonghuyen2005@gmail.com AI Nguyen Lam Anh Artifical Intelligent nguyenla110505@gmail.com AI Nguyen Van Linh Artifical Intelligent nguyenvanlinh.1710.it@gmail.com SE Bui Nguyen Tan Khang Software Engineering tankhang6a6@gmail.com "
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.1-workshop-overview/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "SorcererXtreme AI: Building an AI-Powered Metaphysical Guidance Platform on AWS The core purpose of this project, for a developer workshop, is to demonstrate how to build a scalable, cost-optimized, multi-faceted application capable of handling complex data flows entirely within the cloud environment.\nProblem Solved \u0026amp; Technical Value The Challenge: Building a platform that combines the need for precise computation with the linguistic creativity of AI, while ensuring all content is verifiable and grounded. Traditional server-based solutions often struggle with the dynamic scaling required for such varied workloads. The Technical Solution: We solve this by implementing a Retrieval-Augmented Generation (RAG) Core utilizing Amazon Bedrock and Pinecone. This design allows the AI to produce verified answers based on a specialized knowledge base, transforming speculative guidance into actionable insights. Key Technical Highlights This project serves as an essential case study for integrating the following critical AWS services:\nServerless Compute: We utilize AWS Lambda as the entire Backend, eliminating server management overhead and significantly optimizing costs. Modern Deployment (Frontend Hosting): Deploying the Next.js application on AWS Amplify provides streamlined CI/CD and hosting for the Frontend. Durable Asynchronous Flow (Async): We constructed a reliable automated reminder system using EventBridge -\u0026gt; Lambda -\u0026gt; SES. This pattern ensures robust, scalable bulk delivery without overloading the core API. Data Persistence and Vectors: We manage complex relational data externally using NeonDB (Serverless PostgreSQL) while utilizing a specialized Vector Database (Pinecone) for the high-speed RAG retrieval layer. Security and DevOps: AWS Parameter Store manages all sensitive keys, and the entire infrastructure is deployed using the Serverless Framework driven by GitHub Actions (CI/CD). Best Practices Learned Attendees will learn how to implement a fully Serverless Microservices architecture, address challenges like external database connectivity, splitting synchronous/asynchronous workloads, and building a cost-effective RAG Core solution.\n"
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.3-backend-development/2.3.1-prepare/",
	"title": "Preparation",
	"tags": [],
	"description": "",
	"content": "1. Technologies Used Category Technology Detail \u0026amp; Role Language TypeScript (Node.js 20) Primary language, providing Type Safety. Backend Core Express.js + serverless-http Familiar API Framework, \u0026ldquo;wrapped\u0026rdquo; to run on Lambda. Infrastructure (IaC) Serverless Framework V4 Main tool for defining and deploying the entire AWS architecture. Compute AWS Lambda Handles business logic and runs the TypeScript code. API Gateway AWS API Gateway Synchronous HTTP communication gateway for the entire Backend. Database NeonDB (Serverless PostgreSQL) Primary database for relational data. ORM Prisma Abstraction Layer between the code and the database. Security AWS SSM Parameter Store Secure storage for sensitive environment variables. DevOps GitHub Actions Automates the CI/CD pipeline. 2. Required Resources \u0026amp; Software To complete the workshop, users must have the following tools and accounts ready on their computer.\nA. Account Requirements AWS Account: Necessary for deploying Serverless services (Lambda, API Gateway, SSM). NeonDB Account: Necessary for creating and retrieving the connection string (DATABASE_URL) for the PostgreSQL database. GitHub Account: Necessary for storing the source code and setting up CI/CD (GitHub Actions). B. Local Software \u0026amp; Tools Node.js (v20+): Installed and accessible via the terminal. npm or yarn: Package manager. AWS CLI: Necessary to configure AWS access permissions from the local machine for the Serverless Framework. IDE (VS Code): Recommended development environment. Postman/Insomnia: Essential tool for testing API Endpoints (GET/POST). C. Project Setup Serverless Framework CLI: Must be installed globally (npm install -g serverless). AWS Credentials: Configure AWS access permissions (User/Role) on the local machine. "
},
{
	"uri": "http://localhost:1313/repo-name/1-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "SorcererXStreme: An AI-Powered Metaphysical Guidance Platform 1. Executive Summary The SorcererXStreme AI platform is a unified AI-driven spiritual guidance system designed to help users explore self-discovery through various Eastern and Western esoteric disciplines, including Astrology, Tarot, Numerology, and Eastern Horoscopes. The foundation of the system is the Retrieval-Augmented Generation (RAG) Core, which ensures all output is grounded in curated esoteric knowledge sources.\n2. Problem Statement What’s the Problem? Users currently face several limitations when exploring spiritual and esoteric knowledge:\nFragmented and Unverified Information: Information is scattered across the internet and often lacks credibility or proper cross-referencing. Difficulty in Cross-Discipline Comparison: Results are hard to compare between Eastern (e.g., Eastern Horoscope) and Western (e.g., Astrology) schools of thought. Lack of Personalization and Interaction: Most applications offer static readings, lacking the depth of personalized dialogue and contextual advice. Shallow Content: Many \u0026ldquo;fun\u0026rdquo; apps lack intellectual depth and robust knowledge. The Solution SorcererXStreme AI offers a unified, intuitive, and intelligent platform:\nDirect Interaction: Users chat directly with AI Chatbot, asking anything about their personality, fate, or relationships. RAG-Grounded Interpretations: The core RAG system guarantees that interpretations are based on verified esoteric data, ensuring accuracy and depth. Tiered User Experience: Free and VIP tiers optimize the user experience and create a revenue stream. Cost-Efficient Design: A modern, lightweight design rapidly deployed on a cost-optimized AWS serverless architecture. Benefits and Return on Investment Benefit Impact Value Data Reliability RAG reduces AI \u0026ldquo;hallucinations\u0026rdquo; and provides verifiable interpretations. High Trust \u0026amp; better user retention. Centralization Consolidates Eastern and Western mystical data in one platform. Unified Knowledge base for users. Monetization VIP subscription model unlocks advanced features. Stable Revenue stream and business viability. Operational Cost Serverless AWS architecture is used. Estimated $80–$90/month for MVP . 3. Solution Architecture The SorcererXStreme AI platform utilizes a robust, hybrid serverless architecture on AWS, meticulously designed to handle real-time user interactions, scheduled tasks, and autonomous monitoring.\nServices Used Layer Service Role and Relationship Edge \u0026amp; Auth Amplify, Cognito - Amplify handles frontend hosting and routing.\n- Cognito manages authentication. API \u0026amp; Routing API Gateway - The primary endpoint for all Backend Lambdas and AI Lambdas. Compute Layer AWS Lambda - Processes Business Logic and Async/Sync flows. Data \u0026amp; Integration DynamoDB, Parameter Store, NeonDB, Pinecone - NeonDB (external PostgreSQL) is the Primary DB.\n- DynamoDB for history/quick access.\n- Parameter Store for secure storage. AI/ML Bedrock, Lambda (Embeddings), S3 - Bedrock (LLM Model).\n- S3 stores raw RAG documents.\n- Lambda Embeddings creates vectors. Async \u0026amp; Monitoring EventBridge, SQS, SES, CloudWatch, SNS - Handles Asynchronous flows and Independent Monitoring activities. DevOps GitHub Actions, CloudFormation - GitHub Actions handles Build and Test process, and CloudFormation generated by the Serverless Framework is the main deployment tool. Workflow 1. Real-time API Interaction Flow (Synchronous Flow) This flow handles direct chat and interpretation requests from the user.\n(1) Request Reception: The User sends a request directly to the AWS Amplify Endpoint. (2) Routing \u0026amp; API: Amplify forwards the request to API Gateway. API Gateway authenticates the Cognito token and routes to the corresponding Lambda (SyncUser, Chatbot, etc.). (3) Data Processing: Lambda accesses Parameter Store for secrets and retrieves data from NeonDB, DynamoDB. (4) RAG and AI: The Chatbot Lambda executes the RAG flow: Uses Bedrock (Embedding Model) to create a vector for the question. Queries Pinecone (Vector Database) using that vector. Sends the RAG context to Bedrock (LLM) to generate the answer. (5) Response: Lambda returns the result to API Gateway -\u0026gt; Amplify -\u0026gt; User. 2. Automated Notification Flow (Asynchronous Flow) This flow is simplified and does not require RDS.\n(1) Trigger: EventBridge Scheduler triggers the TriggerReminder Lambda. (2) Data Query: Lambda queries DynamoDB or NeonDB to retrieve the list of subscribed users. (3) Distribution: Lambda generates content and sends emails via Amazon SES. 3. Deployment Flow (DevOps) (1) Code Commit: Developer pushes code to GitHub. (2) Build \u0026amp; Deploy: GitHub Actions triggers the Build, Test process and uses CloudFormation generated by the Serverless Framework to deploy Lambdas, API Gateway, and other resources to AWS. 5. Timeline \u0026amp; Milestones The SorcererXStreme project will be executed over a 9-week concentrated development period using an Agile-Iterative model to quickly deliver an MVP with key features.\nProject Timeline Iteration Duration Week Primary Focus Key Deliverables Iter 3: Redesign \u0026amp; RAG Prototype 3 Weeks 1 – 2 – 3 Platform Design \u0026amp; Documentation - SRS v2 and SDS v2, Proposal finalized.\n- AWS Architecture Diagram and cost estimate sheet.\n- RAG data collected and initial pipeline designed. Iter 4: Roles \u0026amp; VIP System 3 Weeks 4 – 5 – 6 Core Logic \u0026amp; Authorization Implementation - AWS Cognito integrated for user authentication.\n- Full Guest/Free/VIP role logic implemented and testable.\n- RAG data corpus built on S3. Iter 5: AWS Deployment \u0026amp; QA 3 Weeks 7 – 8 – 9 Cloud Deployment \u0026amp; Stabilization - System running stably on AWS.\n- Full end-to-end testing completed. AWS Cost and Performance Sheet finalized.\n- Ready for production environment. 6. Budget Estimate The project is estimated based on low usage for a Demo environment (approx. 5,000 requests/month).\nInfrastructure Costs Layer AWS Service Purpose Cost I. COMPUTE \u0026amp; API 1 AWS Lambda Backend Logic Processing (RAG, Compute) $0.00 2 Amazon API Gateway Synchronous Request Gateway $0.025 3 AWS Amplify Frontend Host (Next.js) $2.59 II. DATA \u0026amp; STORAGE 4 Amazon DynamoDB Chat History/Rate Limiting $0.89 5 Amazon S3 RAG Knowledge Base/Assets $0.03 III. AI \u0026amp; SECURITY 6 Amazon Bedrock Embedding \u0026amp; LLM/Content Generation $2.65 7 Amazon Cognito Authentication/User Roles $0.00 8 Parameter Store Store Master Keys $0.00 IV. ASYNC \u0026amp; MONITORING 9 EventBridge Scheduler Daily Horoscope Trigger $0.00 10 Amazon SES Email Delivery $0.48 11 Amazon CloudWatch Logs/Metrics/Alarms $2.4 12 Amazon SNS Alert Notifications $0.00 13 Cloudformation Deploy for dev $0.00 Link: Cost Estimation Sheet\nTotal Project Cost: $9.06/month 7. Risk Assessment Risk Matrix Risk Impact Probability Mitigation Strategy LLM Hallucination High Medium Implement RAG Fact Checker; use high-quality LLMs; ground answers in verified sources. Cost Overruns (LLM Calls) High Medium Set up AWS Budget Alerts; implement token control; use tiered LLM models (Free vs. VIP). RAG Retrieval Latency Medium Medium Optimize RAG indexing; optimize chunk size and embedding model choice. Security Breaches High Low Use Cognito for authentication and Secret Manager for credential handling. 8. Expected Outcomes Technical Improvements Real-time Accuracy: RAG integration significantly reduces AI \u0026ldquo;hallucinations,\u0026rdquo; enhancing the reliability of interpretations. Scalability: The serverless AWS architecture ensures automatic scaling to handle significant user traffic. Long-term Value Monetization: The VIP subscription model creates a clear, stable path for revenue generation. Data Foundation: A proprietary, verified esoteric knowledge base (RAG corpus) is established as a valuable, reusable asset. Future Expansion: The flexible AWS architecture (Lambda, Bedrock) is easily upgradable for mobile apps (React Native) or voice chat features. "
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "SorcererXtreme: Building an AI-Powered Metaphysical Guidance Platform on AWS Overview SorcererXtreme AI is a pioneering metaphysical guidance platform that leverages AI and a robust AWS Serverless architecture to deliver personalized, grounded, and reliable readings across Astrology, Tarot, Horoscope and Numerology.\nContent Workshop overview Frontend Development Backend Development AI Development "
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.3-backend-development/2.3.2-set-up/",
	"title": "Setup environment",
	"tags": [],
	"description": "",
	"content": "Step 1: Project Initialization \u0026amp; Library Installation Create the project directory and install all the necessary core dependencies.\n# Create the main directory for the Backend mkdir my-serverless-backend \u0026amp;\u0026amp; cd my-serverless-backend # Initialize a Node.js package npm init -y # Install Core Dependencies: Express, Prisma Client, Serverless-HTTP, etc. npm install express cors dotenv @prisma/client axios serverless-http # Install Development Dependencies: TypeScript, Types for Node/Express, Prisma CLI, Serverless-Offline npm install -D typescript @types/node @types/express serverless-offline prisma serverless-dotenv-plugin Step 2: TypeScript \u0026amp; Directory Structure Setup Configure TypeScript and create the standard directory structure.\nInitialize tsconfig.json: npx tsc --init Edit tsconfig.json: Open the tsconfig.json file and adjust the following settings to ensure modern Node.js source code and compatibility with Lambda: \u0026quot;target\u0026quot;: \u0026quot;ES2020\u0026quot; (or newer) \u0026quot;module\u0026quot;: \u0026quot;commonjs\u0026quot; \u0026quot;outDir\u0026quot;: \u0026quot;./dist\u0026quot; (Output directory for compiled code) \u0026quot;rootDir\u0026quot;: \u0026quot;./src\u0026quot; (Source code directory) \u0026quot;esModuleInterop\u0026quot;: true \u0026quot;strict\u0026quot;: true Create Directory Structure: mkdir src src/routes src/services src/controllers Step 3: Code Restructuring (Express -\u0026gt; Lambda) Since Lambda does not \u0026ldquo;listen\u0026rdquo; on a standard port, we use serverless-http to wrap Express.\nFile src/app.ts (Core Express App):\nimport express from \u0026#39;express\u0026#39;; import cors from \u0026#39;cors\u0026#39;; import routes from \u0026#39;./routes/index\u0026#39;; // Change to index if you use routes/index.ts const app = express(); // 1. Basic Middlewares app.use(cors({ origin: process.env.FRONTEND_URL || \u0026#39;*\u0026#39; })); app.use(express.json()); // 2. API Routing (Main Endpoint will be /api/...) app.use(\u0026#39;/api\u0026#39;, routes); // IMPORTANT: Do not use app.listen(), eliminate traditional web server logic. export default app; File src/handler.ts (Lambda Bridge):\nimport serverless from \u0026#34;serverless-http\u0026#34;; import app from \u0026#34;./app\u0026#34;; // Export the main handler that AWS Lambda will call export const handler = serverless(app); Step 4: Configure Prisma \u0026amp; NeonDB Connection To connect to NeonDB and ensure the Prisma Client works in the AWS Lambda Linux environment, the binaryTargets must be configured.\nCreate Schema File \u0026amp; Configure binaryTargets: npx prisma init Open the file prisma/schema.prisma and add the configuration: generator client {\rprovider = \u0026#34;prisma-client-js\u0026#34;\r// native: For the dev machine (Mac/Win)\r// rhel-openssl-3.0.x: For AWS Lambda (Node 20)\rbinaryTargets = [\u0026#34;native\u0026#34;, \u0026#34;rhel-openssl-3.0.x\u0026#34;] }\rdatasource db {\rprovider = \u0026#34;postgresql\u0026#34;\rurl = env(\u0026#34;DATABASE_URL\u0026#34;)\r}\r// ... model definitions (User, Partner, Reminder, etc.) Create Local .env file: Create the .env file and paste your NeonDB connection string into it. # Get the PostgreSQL connection string from the Neon Console DATABASE_URL=\u0026#34;postgresql://[user]:[password]@[endpoint]/[dbname]?sslmode=require\u0026#34; Generate Prisma Client: Run the following command to create the Prisma Client and download the necessary binaries. npx prisma generate Complete: Your local environment is now ready. You can compile the code (npm run build) and run local tests with serverless-offline.\n"
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.3-backend-development/2.3.3-configure-serverless/",
	"title": "Configure Serverless Framework",
	"tags": [],
	"description": "",
	"content": "This is the most crucial step, where we define the AWS infrastructure (IaC) and optimize the deployment package for Lambda.\n1. The serverless.yml File This configuration file includes sections for SSM Security, Build/Package Optimization, and necessary IAM Roles.\n# serverless.yml org: your_organization_name service: my-serverless-backend # Ensure service name matches the directory provider: name: aws runtime: nodejs20.x region: ap-southeast-1 timeout: 29 # Maximum allowed by API Gateway (keep as is) memorySize: 512 # Lambda memory configuration (recommended for Prisma) # --- VPC Network Configuration (MANDATORY for NeonDB) --- # If NeonDB requires a fixed IP or you use an internal RDS, # Lambda needs VPC configuration to connect externally or within the VPC. # (Assumed for NeonDB Public Access, but VPC needed if using Private Subnet) # vpc: # securityGroupIds: [sg-xxxxxxxx] # subnetIds: [subnet-xxxxxx] # --- Environment Variables (Fetched from SSM) --- environment: # Retrieve secrets from AWS SSM Parameter Store (Encrypted) DATABASE_URL: ${ssm:/my-app/${self:provider.stage}/database_url} JWT_SECRET: ${ssm:/my-app/${self:provider.stage}/jwt_secret} FRONTEND_URL: ${ssm:/my-app/${self:provider.stage}/frontend_url, \u0026#39;http://localhost:3000\u0026#39;} # Add local fallback PRISMA_CLI_BINARY_TARGETS: rhel-openssl-3.0.x # Crucial for Prisma # --- IAM Permissions (Required) --- # Add necessary permissions for Lambda to read SSM and access other services iam: role: statements: - Effect: \u0026#39;Allow\u0026#39; Action: - \u0026#39;ssm:GetParameter\u0026#39; Resource: \u0026#39;arn:aws:ssm:${self:provider.region}:*:parameter/my-app/${self:provider.stage}/*\u0026#39; # --- DDoS/Billing Protection (Keep as is) --- apiGateway: usagePlan: quota: limit: 5000000 period: MONTH throttle: burstLimit: 200 rateLimit: 100 # --- Deployment Package Size Optimization --- build: esbuild: bundle: true minify: true sourcemap: false # Explicitly specify modules to exclude from the main package external: - \u0026#39;aws-sdk\u0026#39; - \u0026#39;@prisma/client/runtime/library\u0026#39; package: individually: true patterns: - \u0026#39;src/handler.js\u0026#39; - \u0026#39;src/app.js\u0026#39; - \u0026#39;src/**/*.js\u0026#39; - \u0026#39;dist/**/*.js\u0026#39; # Ensure compiled JS files are packaged - \u0026#39;package.json\u0026#39; - \u0026#39;node_modules/**\u0026#39; # --- Define Prisma Binary Files (Extremely important) --- # Only include the necessary Linux binary file to keep package \u0026lt; 250MB - \u0026#39;node_modules/.prisma/client/libquery_engine-rhel-openssl-3.0.x.so.node\u0026#39; - \u0026#39;node_modules/.prisma/client/schema.prisma\u0026#39; - \u0026#39;!./**\u0026#39; # Remove all unnecessary files after defining required patterns above - \u0026#39;!node_modules/aws-sdk/**\u0026#39; # Reduce size by excluding SDK already available in Lambda plugins: - serverless-offline - serverless-dotenv-plugin functions: api: handler: src/handler.handler events: - http: { path: /, method: ANY } - http: { path: /{proxy+}, method: ANY } 2. Required Steps A. Store Secrets in AWS SSM (Security) Before deployment, you must store sensitive values in the AWS SSM Parameter Store so the Serverless Framework can read them.\n# Command to store DATABASE_URL (SecureString) aws ssm put-parameter \\ --name \u0026#34;/my-app/dev/database_url\u0026#34; \\ --value \u0026#34;postgresql://user:password@endpoint...\u0026#34; \\ --type \u0026#34;SecureString\u0026#34; \\ --overwrite # Repeat for JWT_SECRET and FRONTEND_URL B. Run Local Testing Use the serverless-offline plugin to run the API locally, connecting directly to NeonDB via the .env file.\n# Run local API on port 3000 (default) sls offline start C. First-time Deployment Once the code has been locally tested, you are ready to deploy the entire infrastructure to AWS.\n# Deploy all resources (Lambda, API Gateway, IAM) sls deploy "
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.3-backend-development/2.3.4-aws-ssm/",
	"title": "Storing Sensitive Environment Variables",
	"tags": [],
	"description": "",
	"content": "Storing sensitive environment variables (DATABASE_URL, JWT_SECRET) in AWS Systems Manager (SSM) Parameter Store is the security standard for Serverless applications.\n1. Preparation In your serverless.yml, you used the variable ${self:provider.stage} (defaulting to dev if not specified). To be consistent with that configuration, we should define the Key in the format /my-app/\u0026lt;stage\u0026gt;/\u0026lt;key\u0026gt;.\n2. Run CLI Commands to Store Keys You need to run these commands via the AWS CLI after configuring access permissions.\n# NOTE: Replace \u0026lt;YOUR_VALUE\u0026gt; with your actual value. # We will use the default stage \u0026#34;dev\u0026#34; for the workshop environment. # --- 1. Store NeonDB Connection String --- # Use \u0026#34;SecureString\u0026#34; to encrypt the data. aws ssm put-parameter \\ --name \u0026#34;/my-app/dev/database_url\u0026#34; \\ --value \u0026#34;postgresql://user:pass@ep-xyz.aws.neon.tech/neondb?sslmode=require\u0026#34; \\ --type \u0026#34;SecureString\u0026#34; \\ --overwrite # --- 2. Store JWT Secret --- aws ssm put-parameter \\ --name \u0026#34;/my-app/dev/jwt_secret\u0026#34; \\ --value \u0026#34;a_very_long_and_secure_jwt_key_314159\u0026#34; \\ --type \u0026#34;SecureString\u0026#34; \\ --overwrite # --- 3. Store Frontend URL (If necessary for CORS) --- aws ssm put-parameter \\ --name \u0026#34;/my-app/dev/frontend_url\u0026#34; \\ --value \u0026#34;https://your-amplify-app.amplifyapp.com\u0026#34; \\ --type \u0026#34;String\u0026#34; \\ --overwrite 3. Verification After storing, you can run the following command to check if the Parameter has been saved correctly and if the Serverless Framework can access it:\n# Command to check and decrypt the value (requires SSM Read permission) aws ssm get-parameter \\ --name \u0026#34;/my-app/dev/database_url\u0026#34; \\ --with-decryption Important Note: In serverless.yml, you defined: DATABASE_URL: ${ssm:/my-app/prod/database_url}. To synchronize with the command above, you need to change prod to dev in serverless.yml if you are deploying with the default stage, or run the CLI commands with the prod stage if you wish to keep the serverless.yml file as is.\n"
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.3-backend-development/2.3.5-cicd/",
	"title": "Automation CI/CD",
	"tags": [],
	"description": "",
	"content": "The objective of this section is to establish a process so that every time code is pushed to the main branch, your entire Serverless architecture will be automatically Built, Tested, and Deployed to AWS without manual intervention from a local machine.\n1. Preparing Secrets on the GitHub Repository This is the most crucial step for granting GitHub Actions access to AWS.\nSecret Name Role Notes and Action AWS_ACCESS_KEY_ID AWS Access Key. VERY IMPORTANT: Use an IAM User with minimum necessary permissions (not Admin) to only allow creation/updating of Lambda, API Gateway resources, and reading SSM. AWS_SECRET_ACCESS_KEY Corresponding Secret Key. (Keep as is) SERVERLESS_ACCESS_KEY Serverless Dashboard Key. Only needed if you use Serverless Dashboard management features. If not, this can be omitted. 2. Workflow File .github/workflows/deploy.yml This file defines the steps that GitHub Actions will execute. We will add the Build step and omit environment variables unnecessary for the deploy command.\nname: Deploy Backend CI/CD via Serverless Framework on: push: branches: [ main ] # Triggers when pushing to the main branch workflow_dispatch: # Allows manual triggering from the GitHub UI jobs: deploy: runs-on: ubuntu-latest # Grant permissions for GitHub Actions permissions: id-token: write contents: read steps: - uses: actions/checkout@v4 # 1. Get source code - name: Setup Node 20 uses: actions/setup-node@v3 with: node-version: \u0026#39;20\u0026#39; cache: \u0026#39;npm\u0026#39; # Enable cache to speed up installation - name: Install Dependencies run: npm ci # Use npm ci to ensure consistency (from package-lock.json) # --- PRISMA \u0026amp; CODE BUILD CONFIGURATION --- - name: Generate Prisma Client (download Linux binary) # Download the rhel-openssl-3.0.x binary (necessary for Lambda) run: npx prisma generate - name: Build TypeScript Code (tsc -\u0026gt; dist) # Run the compilation command (assumes a \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34; script in package.json) run: npm run build # --- AWS CONFIGURATION --- - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v4 with: aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: ap-southeast-1 # --- FINAL DEPLOYMENT --- - name: Deploy Serverless # Use npx to call the serverless CLI run: npx serverless deploy env: # Explicitly specify the deployment stage. SLS_STAGE: dev # [Note]: The DATABASE_URL variable is already handled by placeholder or SSM DATABASE_URL: \u0026#34;placeholder\u0026#34; 3. CI/CD Workflow Summary Code Commit: You develop code and perform a git push to GitHub. Trigger: GitHub Actions automatically triggers the deploy.yml workflow. Build \u0026amp; Package: The Ubuntu Runner installs dependencies, runs npx prisma generate (downloading the Linux binary), and compiles the code. AWS Authentication: aws-actions/configure-aws-credentials logs into AWS using your Secret Keys. Provisioning: The npx serverless deploy command reads serverless.yml, connects to SSM Parameter Store to fetch secret keys, and instructs CloudFormation to build/update the entire Lambda and API Gateway infrastructure. "
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.3-backend-development/2.3.6-microservice/",
	"title": "Connect microservices",
	"tags": [],
	"description": "",
	"content": "In a Serverless architecture, when one Lambda function (e.g., Chatbot) needs to call another service (MetaphysicalAPI), the best approach is to use an HTTP request through that service\u0026rsquo;s API Gateway.\n1. Principles of API Calling Endpoint: Always call through the public API Gateway Endpoint (or an internal one if both Lambdas are within a VPC and use a Private API Gateway). Library: Use a familiar HTTP library like axios to manage the request and client-side timeout. Security: Use IAM Roles or API Keys to authenticate calls between services if the API Gateway is not entirely public. 2. Timeout Management Managing the timeout is the most critical factor to prevent 504 Gateway Timeout errors.\n[Image of AWS API Gateway 29-second timeout limit diagram]\nAPI Gateway Limit: The API Gateway has a hard timeout limit of 29 seconds. Any request lasting longer than 29 seconds is cut off and returns a 504 error. Lambda Limit: Lambda can run up to 15 minutes, but it is constrained by the API Gateway. Therefore, the Lambda timeout must be set less than 29 seconds (e.g., 25 seconds). Configuration Location Recommended Value Rationale API Gateway Timeout serverless.yml (Provider level) 29 seconds AWS maximum hard limit. Lambda Timeout (Receiver) serverless.yml (Function level) 25 seconds Must be less than 29s so Lambda can return an error before the API Gateway cuts the connection. Client Timeout (axios) TypeScript Code 25,000 ms (25 seconds) Ensures the client cuts the connection before Lambda times out, allowing for cleaner client-side error handling. 3. Lambda Performance Optimization If your AI Service performs heavy tasks (like RAG, astronomical calculations), optimizing processing speed is mandatory.\nIncrease Memory (RAM): Increase the memorySize of the AI Service Lambda to a higher level (e.g., 1536 MB or 3008 MB). On AWS, increasing RAM also increases CPU and Network Bandwidth, significantly speeding up heavy processing and reducing the likelihood of 504 errors. Code Configuration: Configure timeout: 25 in serverless.yml for both the Backend and the AI Service. 4. Code Example Here is the AI calling function, modified to handle exceptions clearly and adhere to the Timeout principle.\nimport axios from \u0026#39;axios\u0026#39;; // Assume AI_SERVICE_URL is retrieved from AWS SSM Parameter Store and injected into ENV const AI_SERVICE_URL = process.env.AI_SERVICE_URL; const CLIENT_TIMEOUT_MS = 25000; // 25 seconds (Below the 29s API Gateway limit) /** * Calls the AI service\u0026#39;s API Gateway to receive a response. * @param prompt The request data sent to the AI. */ export const callAI = async (prompt: string, userId: string) =\u0026gt; { if (!AI_SERVICE_URL) { throw new Error(\u0026#34;AI Service URL is not configured.\u0026#34;); } try { const res = await axios.post(AI_SERVICE_URL, { prompt, userId // Send user ID so the AI Service can log or handle VIPs }, { timeout: CLIENT_TIMEOUT_MS // Set client timeout }); // Handle successful response return res.data; } catch (error) { if (axios.isAxiosError(error) \u0026amp;\u0026amp; error.code === \u0026#39;ECONNABORTED\u0026#39;) { // Client-side Timeout error console.error(\u0026#34;AI Timeout Error: Request took too long.\u0026#34;); throw new Error(\u0026#34;AI Service timed out (504). Please try again.\u0026#34;); } // Other errors (e.g., 4xx, 5xx from AI Service) console.error(\u0026#34;AI Service Error:\u0026#34;, error.message); throw new Error(\u0026#34;AI Service unavailable or returned an error.\u0026#34;); } }; "
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.3-backend-development/2.3.7-email/",
	"title": "Setup Email",
	"tags": [],
	"description": "",
	"content": "To ensure the highest delivery reliability for project emails and prevent them from being marked as Spam by email service providers (like Gmail, Outlook), domain security configuration is mandatory.\n1. Basic Configuration and Identity Security Step Action Purpose 1. Domain Purchase Use a private domain (.com, .xyz) instead of a shared one. Reputation: Establish a separate email sending reputation, avoiding impact from other bad senders. 2. Verify Domain in AWS SES Access SES -\u0026gt; Verified Identities -\u0026gt; Create Identity (Select Domain). Proof of Ownership: Allows AWS SES to manage email sending on behalf of your domain. 3. Configure DNS (Email Security) Add CNAME (DKIM), TXT (SPF), and TXT (DMARC) records. Crucial: These records verify the sending source (DKIM/SPF) and instruct the receiving server how to handle invalid emails (DMARC), preventing emails from falling into Spam. Details of Mandatory DNS Records: DKIM (CNAME): Add the 3 CNAME records provided by AWS SES. Purpose: Digital Signature. SPF (TXT): Add a TXT record with the content: v=spf1 include:amazonses.com ~all. Purpose: Designates AWS SES as an authorized server to send mail. DMARC (TXT): Add a TXT record (usually as _dmarc) with the content: v=DMARC1; p=none;. Purpose: Establishes reporting and handling policies for fraudulent emails. 2. Setting up the Sending Flow and Exiting Sandbox After the domain has been verified (Verification Status: Verified), you need to set up the operational flow and request actual sending permission.\nStep Interacting Service Action 1. Activate Async Flow EventBridge Scheduler -\u0026gt; Lambda (TriggerReminder) The asynchronous flow starts according to a defined schedule. 2. Send SES Request Lambda (TriggerReminder) -\u0026gt; Amazon SES API The Lambda function (with the granted IAM Role) directly calls the SES API (e.g., SendEmailCommand) to send personalized emails to each user. 3. Request Production Access AWS Support Center Submit a ticket requesting AWS to upgrade your account from Sandbox mode so you can send emails to any unverified address. "
},
{
	"uri": "http://localhost:1313/repo-name/2-workshop/2.3-backend-development/2.3.8-summary/",
	"title": "Development workflow",
	"tags": [],
	"description": "",
	"content": "The workflow is designed to leverage the speed of local development and the safety and automation of the Serverless architecture.\nStep Activity Environment Role and Notes 1. Code Development Code logic, API modifications (TypeScript/Express). Local Machine Use VS Code and Node.js libraries. 2. Local Testing Test synchronous APIs. sls offline start Simulates the Lambda/API Gateway environment. Connects directly to NeonDB via the local .env file. 3. Database Schema Update If Schema is modified (schema.prisma). npx prisma migrate dev Creates Migration and applies changes. 4. Commit \u0026amp; Push Code Commit code and push to the repository. git push origin main Triggers the automated CI/CD flow. 5. Automated CI/CD Deployment to the Cloud. GitHub Actions Automated: Build -\u0026gt; Prisma Generate -\u0026gt; AWS/SSM Login (fetch Keys) -\u0026gt; Deploy to AWS Lambda. 6. Error Monitoring Check Real-time Logs. sls logs -f api -t Use the Serverless Framework command to immediately view CloudWatch Logs and debug errors in the Production/Staging environment. Important Notes on Prisma: Use migrate dev: Instead of db push (which is only for non-production/test), you should use npx prisma migrate dev to create a history of changes (migration files) and apply them to NeonDB. Generate on CI/CD: Running npx prisma generate in GitHub Actions is mandatory to download the necessary binaries (rhel-openssl-3.0.x) for the AWS Lambda Linux environment. "
},
{
	"uri": "http://localhost:1313/repo-name/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/repo-name/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]