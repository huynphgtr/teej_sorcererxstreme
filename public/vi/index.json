[
{
	"uri": "http://localhost:1313/repo-name/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Thông tin Nhóm thực tập Thông Tin Dự Án Thông tin Chi tiết Tên nhóm TEEJ_SorcererXStreme Trường Đại học FPT - Hồ Chí Minh Campus Công ty thực tập Công ty TNHH Amazon Web Services Việt Nam Vị trí thực tập Thực tập sinh chương trình FCJ Workforce Thời gian thực tập Từ ngày 08/09/2025 đến 24/12/2025 Thành Viên Nhóm Ảnh Vai trò Họ và Tên Chuyên ngành Liên hệ Trưởng nhóm Trần Phương Huyền Kỹ thuật phần mềm tranphuonghuyen2005@gmail.com AI Nguyễn Lâm Anh Trí tuệ nhân tạo nguyenla110505@gmail.com AI Nguyễn Văn Linh Trí tuệ nhân tạo nguyenvanlinh.1710.it@gmail.com SE Bùi Nguyễn Tấn Khang Kỹ thuật phần mềm tankhang6a6@gmail.com "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.3-backend-development/2.3.1-prepare/",
	"title": "Chuẩn bị",
	"tags": [],
	"description": "",
	"content": "1. Công Nghệ Sử Dụng Hạng mục Công nghệ Chi tiết \u0026amp; Vai trò Ngôn ngữ TypeScript (Node.js 20) Ngôn ngữ chính, cung cấp khả năng kiểm soát kiểu (Type Safety). Backend Core Express.js + serverless-http Framework API quen thuộc, được \u0026ldquo;đóng gói\u0026rdquo; để chạy trên Lambda. Hạ tầng (IaC) Serverless Framework V4 Công cụ chính để định nghĩa và triển khai toàn bộ kiến trúc AWS. Compute AWS Lambda Xử lý logic nghiệp vụ và chạy mã TypeScript. API Gateway AWS API Gateway Cổng giao tiếp HTTP đồng bộ cho toàn bộ Backend. Database NeonDB (Serverless PostgreSQL) Database chính cho dữ liệu quan hệ ORM Prisma Lớp trừu tượng hóa (Abstraction Layer) giữa code và database. Bảo mật AWS SSM Parameter Store Nơi lưu trữ an toàn các biến môi trường nhạy cảm. DevOps GitHub Actions Tự động hóa quy trình CI/CD. 2. Tài Nguyên \u0026amp; Phần Mềm Cần Chuẩn Bị Để thực hiện workshop, người dùng cần có sẵn các công cụ và tài khoản sau trên máy tính của mình.\nA. Yêu cầu Tài khoản (Accounts) Tài khoản AWS: Cần thiết để triển khai các dịch vụ Serverless (Lambda, API Gateway, SSM). Tài khoản NeonDB: Cần thiết để tạo và lấy chuỗi kết nối (DATABASE_URL) cho database PostgreSQL. Tài khoản GitHub: Cần thiết cho việc lưu trữ mã nguồn và thiết lập CI/CD (GitHub Actions). B. Phần Mềm \u0026amp; Công Cụ Local Node.js (v20+): Đã được cài đặt và có thể truy cập qua terminal. npm hoặc yarn: Trình quản lý gói. AWS CLI: Cần thiết để cấu hình quyền truy cập AWS từ máy local và Serverless Framework. IDE (VS Code): Môi trường phát triển được khuyến nghị. Postman/Insomnia: Công cụ cần thiết để kiểm tra các API Endpoint (GET/POST). C. Thiết lập Dự án Serverless Framework CLI: Cần được cài đặt toàn cục (npm install -g serverless). AWS Credentials: Cấu hình quyền truy cập AWS (User/Role) trên máy local. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.2-frontend-development/2.2.1-preparation/",
	"title": "Chuẩn bị môi trường phát triển",
	"tags": [],
	"description": "",
	"content": "1. Cài đặt công cụ (Prerequisites) Để phát triển ứng dụng web hiện đại, bạn cần chuẩn bị các công cụ tiêu chuẩn sau:\nNode.js (LTS Version): Môi trường runtime cho JavaScript/TypeScript. Git: Hệ thống quản lý phiên bản phân tán. IDE: Visual Studio Code (khuyên dùng). VS Code Extensions khuyến nghị:\nESLint \u0026amp; Prettier: Tự động format và kiểm tra lỗi code. Tailwind CSS IntelliSense: Gợi ý class Tailwind cực nhanh. ES7+ React/Redux/React-Native snippets: Code nhanh hơn với các phím tắt. 2. Khởi tạo dự án Next.js Chúng ta sẽ sử dụng Next.js - React Framework phổ biến nhất hiện nay.\nChạy lệnh khởi tạo:\nnpx create-next-app@latest my-serverless-app Cấu hình chi tiết:\nTypeScript: Yes (Tăng tính chặt chẽ cho code) Tailwind CSS: Yes (Styling nhanh chóng) ESLint: Yes (Kiểm tra lỗi) App Router: Yes (Kiến trúc routing mới nhất) Import Alias: @/ (Giúp import file gọn gàng hơn) 3. Khởi tạo AWS Amplify (Backend) Đây là bước quan trọng để tích hợp các tính năng Serverless (Auth, Data) vào dự án. Chạy lệnh sau trong thư mục dự án:\ncd my-serverless-app npm create amplify@latest Khi được hỏi cài đặt, chọn Yes. Amplify sẽ tự động tạo thư mục amplify/ chứa cấu trúc Backend.\n4. Cài đặt thư viện AWS Cài đặt các gói SDK cần thiết để Frontend giao tiếp với AWS:\nnpm install aws-amplify @aws-amplify/ui-react 5. Cấu trúc dự án chuẩn (Project Structure) Sau khi cài đặt xong, cấu trúc thư mục sẽ trông như sau:\namplify/: Chứa code Backend (auth.ts, data.ts). src/app: Chứa các Pages và Layout (App Router). src/components: Chứa các UI Components tái sử dụng. amplify_outputs.json: File cấu hình tự động sinh ra (Không sửa file này). 6. Cấu hình tsconfig.json (Best Practices) Để đảm bảo code TypeScript chặt chẽ nhất, hãy cập nhật tsconfig.json:\n{ \u0026#34;compilerOptions\u0026#34;: { \u0026#34;target\u0026#34;: \u0026#34;es5\u0026#34;, \u0026#34;lib\u0026#34;: [\u0026#34;dom\u0026#34;, \u0026#34;dom.iterable\u0026#34;, \u0026#34;esnext\u0026#34;], \u0026#34;allowJs\u0026#34;: true, \u0026#34;skipLibCheck\u0026#34;: true, \u0026#34;strict\u0026#34;: true, \u0026#34;forceConsistentCasingInFileNames\u0026#34;: true, \u0026#34;noEmit\u0026#34;: true, \u0026#34;esModuleInterop\u0026#34;: true, \u0026#34;module\u0026#34;: \u0026#34;esnext\u0026#34;, \u0026#34;moduleResolution\u0026#34;: \u0026#34;node\u0026#34;, \u0026#34;resolveJsonModule\u0026#34;: true, \u0026#34;isolatedModules\u0026#34;: true, \u0026#34;jsx\u0026#34;: \u0026#34;preserve\u0026#34;, \u0026#34;incremental\u0026#34;: true, \u0026#34;plugins\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;next\u0026#34; } ], \u0026#34;paths\u0026#34;: { \u0026#34;@/*\u0026#34;: [\u0026#34;./src/*\u0026#34;] } }, \u0026#34;include\u0026#34;: [\u0026#34;next-env.d.ts\u0026#34;, \u0026#34;**/*.ts\u0026#34;, \u0026#34;**/*.tsx\u0026#34;, \u0026#34;.next/types/**/*.ts\u0026#34;], \u0026#34;exclude\u0026#34;: [\u0026#34;node_modules\u0026#34;] } 7. Cài đặt thư viện UI bổ trợ Để tạo giao diện \u0026ldquo;Mystical\u0026rdquo; đep mắt:\nnpm install framer-motion lucide-react clsx tailwind-merge 8. Cấu hình TailwindCSS Thiết lập biến màu trong tailwind.config.ts:\n// tailwind.config.ts import type { Config } from \u0026#34;tailwindcss\u0026#34;; const config: Config = { content: [ \u0026#34;./src/pages/**/*.{js,ts,jsx,tsx,mdx}\u0026#34;, \u0026#34;./src/components/**/*.{js,ts,jsx,tsx,mdx}\u0026#34;, \u0026#34;./src/app/**/*.{js,ts,jsx,tsx,mdx}\u0026#34;, ], theme: { extend: { colors: { primary: \u0026#34;#432c7a\u0026#34;, secondary: \u0026#34;#764ba2\u0026#34;, accent: \u0026#34;#ffd700\u0026#34;, background: \u0026#34;#1a0b2e\u0026#34;, }, backgroundImage: { \u0026#34;gradient-radial\u0026#34;: \u0026#34;radial-gradient(var(--tw-gradient-stops))\u0026#34;, }, }, }, plugins: [], }; export default config; Chuyện nghề (My Experience) Amplify Gen 2 vs Gen 1: Nếu bạn từng dùng Amplify CLI (Gen 1) với hàng tá câu lệnh amplify add auth, hãy quên nó đi! Gen 2 (chúng ta đang dùng) là Code-First. Bạn định nghĩa Backend bằng TypeScript (trong folder amplify/) thay vì click chuột trên Console. Nó giúp Frontend Dev kiểm soát hạ tầng dễ dàng hơn nhiều.\nKiểm thử \u0026amp; Xác thực (Verification) Test Case: Kiểm tra cài đặt Amplify\nMở file package.json. Tìm trong mục dependencies. Kết quả mong đợi: Phải thấy dòng \u0026quot;aws-amplify\u0026quot;: \u0026quot;^6.x.x\u0026quot; và \u0026quot;@aws-amplify/backend\u0026quot;: \u0026quot;^1.x.x\u0026quot;. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/1-proposal/",
	"title": "Đề Án",
	"tags": [],
	"description": "",
	"content": "\rAWS FIRST CLOUD AI JOURNEY – PROJECT PLAN TEEJ_SorcererXStreme - FPT University - Ho Chi Minh Campus - SORCERERXSTREME 0. PHỤ LỤC BỐI CẢNH VÀ ĐỘNG LỰC\n1.1. Tóm tắt 1.2. Tiêu chí thành công của dự án 1.3. Giả định và tiền đề KIẾN TRÚC GIẢI PHÁP\n2.1. Sơ đồ kiến trúc kỹ thuật 2.2. Kế hoạch kỹ thuật 2.3. Kế hoạch dự án 2.4. Các yếu tố bảo mật HOẠT ĐỘNG VÀ KẾT QUẢ BÀN GIAO\n3.1. Hoạt động và kết quả bàn giao 3.2. Nằm ngoài dự án 3.3. Quy trình đưa vào vận hành PHÂN TÍCH CHI PHÍ THEO DỊCH VỤ\nĐỘI NGŨ\nNGUỒN LỰC VÀ ƯỚC TÍNH CHI PHÍ\nNGHIỆM THU\n1. BỐI CẢNH VÀ ĐỘNG LỰC 1.1 Tóm tắt 1. Bối cảnh khách hàng \u0026amp; Vấn đề Vấn đề: Các nguồn thông tin tâm linh hiện nay đang bị phân mảnh, thiếu kiểm chứng và thiếu tính cá nhân hóa. Người dùng gặp khó khăn khi tìm kiếm các luận giải sâu sắc, đáng tin cậy hoặc so sánh các trường phái tri thức Đông - Tây (ví dụ: Tử vi vs. Chiêm tinh). Động lực: Nhu cầu cấp thiết của khách hàng hiện tại là xây dựng một nền tảng hợp nhất có khả năng cung cấp các nội dung được kiểm định về mặt tri thức, đồng thời duy trì khả năng mở rộng và tối ưu chi phí vận hành. 2. Mục tiêu kinh doanh \u0026amp; Kỹ thuật Loại Mục tiêu Chi tiết\rKinh doanh\r- Cung cấp nội dung có độ tin cậy và chiều sâu vượt trội so với các dịch vụ hiện tại. - Tạo doanh thu từ mô hình dịch vụ trả phí.\rKỹ thuật\r- Đảm bảo độ tin cậy AI :Áp dụng lõi RAG để giảm thiểu \"ảo giác\" của AI. - Khả năng mở rộng: Xây dựng kiến trúc AWS Serverless (Lambda, API Gateway) để dễ dàng đáp ứng lưu lượng truy cập lớn và tối ưu chi phí vận hành (Pay-per-use).\r3. Trường hợp sử dụng Các chức năng chính mà dự án sẽ hỗ trợ người dùng:\nAI Chatbot tương tác sâu: Trò chuyện trực tiếp với AI, có khả năng duy trì ngữ cảnh và kết hợp nhiều trường phái trong một phiên sử dụng duy nhất. Luận giải cá nhân hóa: Cung cấp các báo cáo chuyên sâu dựa trên dữ liệu đầu vào (ngày sinh, nơi sinh, giờ sinh). Thông báo tự động: Gửi các thông báo định kỳ qua email. 4. Tóm tắt dịch vụ tư vấn Dịch vụ chuyên nghiệp sẽ được cung cấp để đạt được các mục tiêu trên bao gồm:\nThiết kế Kiến trúc Serverless: Xây dựng kiến trúc đa mô hình và thiết lập luồng RAG trên AWS Bedrock. Tối ưu hóa Chi phí \u0026amp; Hiệu suất: Tinh chỉnh các hàm Lambda và thiết lập bảo mật qua SSM Parameter Store. Tự động hóa CI/CD: Triển khai toàn bộ quy trình phát triển và triển khai tự động (IaC) bằng Serverless Framework và GitHub Actions. 1.2 Tiêu chí thành công của dự án Sự thành công của dự án sẽ được đánh giá dựa trên các tiêu chí định lượng và định tính sau:\nĐộ tin cậy dữ liệu: Hệ thống RAG hoạt động chính xác, giảm thiểu ảo giác AI, cung cấp nguồn dẫn chứng minh bạch cho các luận giải. Hợp nhất tri thức: Thành công trong việc tích hợp dữ liệu huyền học Đông và Tây vào một nền tảng duy nhất. Hiệu quả kinh doanh: Triển khai thành công mô hình phân tầng (Free/VIP) để tạo dòng doanh thu ổn định. Tối ưu chi phí: Hệ thống vận hành trên kiến trúc Serverless với chi phí ước tính khoảng $9.06/tháng cho môi trường Demo. Khả năng mở rộng: Hệ thống tự động mở rộng (Auto-scaling) để xử lý lưu lượng truy cập lớn mà không cần can thiệp thủ công. 1.3 Giả định và tiền đề Dự án được thực hiện dựa trên các giả định và ràng buộc sau:\nPhụ thuộc công nghệ: Dự án phụ thuộc vào tính sẵn sàng và ổn định của các dịch vụ AWS (Bedrock, Lambda, API Gateway). Dữ liệu: Giả định rằng dữ liệu đầu vào cho RAG (sách, tài liệu huyền học) là sạch, có bản quyền hoặc thuộc phạm vi sử dụng hợp lệ. Rủi ro: Có rủi ro về \u0026ldquo;ảo giác\u0026rdquo; của LLM dù đã dùng RAG, cần có cơ chế Fact Checker. Ràng buộc chi phí: Ngân sách vận hành được tối ưu hóa chặt chẽ. 2. KIẾN TRÚC GIẢI PHÁP 2.1 Sơ đồ kiến trúc kỹ thuật Kiến trúc đề xuất là Hybrid Serverless trên AWS, bao gồm các lớp: Edge \u0026amp; Auth, API \u0026amp; Routing, Compute, Data, AI/ML và Async Monitoring.\nCác thành phần chính:\nFrontend: AWS Amplify (Next.js). Auth: Amazon Cognito. Backend: AWS Lambda, Amazon API Gateway. Database: NeonDB (PostgreSQL) làm DB chính, DynamoDB cho lịch sử, Pinecone cho Vector Search. AI Core: Amazon Bedrock (LLM \u0026amp; Embeddings), S3 (RAG Docs). 2.2 Kế hoạch kỹ thuật Đội ngũ dự án sẽ phát triển và triển khai hệ thống theo quy trình kỹ thuật sau:\nScripts \u0026amp; IaC: Sử dụng Serverless Framework để sinh ra CloudFormation template, đảm bảo việc triển khai hạ tầng (IaC) có thể lặp lại và nhất quán. CI/CD: Sử dụng GitHub Actions để tự động hóa quy trình Build, Test và Deploy các hàm Lambda và API Gateway. RAG Pipeline: Thiết lập luồng xử lý dữ liệu: Upload tài liệu lên S3 -\u0026gt; Lambda Trigger -\u0026gt; Tạo Embedding (Bedrock) -\u0026gt; Lưu vào Pinecone Vector DB. 2.3 Kế hoạch dự án Dự án áp dụng mô hình Agile-Iterative trong 9 tuần, chia làm 3 giai đoạn (Iteration) chính:\nIter 3 (Tuần 1-3): Thiết kế lại hệ thống, hoàn thiện tài liệu SRS/SDS và dựng Prototype cho RAG pipeline. Iter 4 (Tuần 4-6): Tích hợp AWS Cognito, phát triển logic phân quyền (Guest/VIP), xây dựng kho dữ liệu (Corpus) trên S3. Iter 5 (Tuần 7-9): Triển khai toàn diện lên AWS, kiểm thử End-to-End (QA), tối ưu hóa chi phí và hiệu năng. 2.4 Các yếu tố bảo mật Bảo mật được thiết kế theo mô hình \u0026ldquo;Defense in Depth\u0026rdquo;:\nIdentity \u0026amp; Access: Sử dụng Amazon Cognito để quản lý định danh và phân quyền người dùng (User Roles). Data Protection: Các khóa bí mật (API Keys, DB Credentials) được lưu trữ an toàn trong AWS Systems Manager Parameter Store, không lưu cứng trong code. Network Security: API Gateway đóng vai trò là cửa ngõ duy nhất. Monitoring: Sử dụng CloudWatch để ghi log và giám sát các hành vi bất thường. 3. HOẠT ĐỘNG VÀ KẾT QUẢ BÀN GIAO 3.1 Activities and deliverables Giai đoạn triển khai Timeline Hoạt động Milestones Ngày hoàn thành Design \u0026amp; Prototype Tuần 1-3 - Thiết kế kiến trúc AWS.\n- Thu thập dữ liệu RAG.\n- Viết tài liệu SRS/SDS. - Sơ đồ kiến trúc \u0026amp; Bảng chi phí.\n- RAG Pipeline Prototype.\n- Tài liệu đề án. 12/10/-01/11/2025 Development (Core) Tuần 4-6 - Tích hợp Cognito.\n- Code Backend (Lambda).\n- Xây dựng Vector DB. - Hệ thống Auth hoạt động.\n- API hoàn chỉnh cho VIP/Free.\n- RAG Knowledge Base sẵn sàng. 02/11-22/11/2025 Deployment \u0026amp; QA Tuần 7-9 - Cấu hình GitHub Actions.\n- Deploy lên môi trường Prod.\n- Load Test \u0026amp; Pen Test. - Hệ thống Live trên AWS.\n- Báo cáo kiểm thử.\n- Tài liệu hướng dẫn sử dụng. 23/11-09/12/2025 3.2 Nằm ngoài dự án Các hạng mục sau nằm ngoài phạm vi của dự án (MVP) hiện tại:\nPhát triển ứng dụng di động (Mobile App - iOS/Android). Tính năng Voice Chat thời gian thực (trò chuyện bằng giọng nói). 3.3 Quy trình đưa vào vận hành Phiên bản hiện tại là MVP (Minimum Viable Product). Để đưa vào sản xuất quy mô lớn, cần thực hiện thêm các bước:\nMở rộng tính năng: Nâng cấp kiến trúc Lambda và Bedrock để hỗ trợ React Native Mobile App hoặc Voice Chat trong tương lai. Operational Excellence: Thiết lập AWS CloudWatch Alarms chi tiết hơn để giám sát lỗi và độ trễ. Tối ưu RAG: Tinh chỉnh kích thước chunk và chiến lược truy xuất để giảm độ trễ phản hồi. 4. PHÂN TÍCH CHI PHÍ THEO DỊCH VỤ Chi phí ước tính cho môi trường Demo (~5.000 requests/tháng) là $9.06/tháng.\nLink chi tiết: Bảng ước tính chi phí\nLayer AWS Service Purpose Cost/Month Compute \u0026amp; API AWS Lambda, API Gateway, Amplify Backend Logic \u0026amp; Hosting ~$2.62 Data \u0026amp; Storage DynamoDB, S3 Chat History \u0026amp; RAG Storage ~$0.92 AI \u0026amp; Security Bedrock, Cognito, Parameter Store LLM Generation \u0026amp; Auth ~$2.65 Async \u0026amp; Monitoring SES, CloudWatch, EventBridge Email \u0026amp; Logging ~$2.88 Tổng $9.06 5. ĐỘI NGŨ Chịu trách nhiệm tổng thể Tên Chức danh Mô tả Email Nguyễn Gia Hưng Head of Architecture Solution Thiết kế và phát triển các nền tảng đám mây gốc và phi máy chủ hunggia@amazon.com Các bên liên quan Tên Chức danh Mô tả Email Đình Quang Sáng PQHDN Đánh giá \u0026amp; Định hướng SangDQ6@fe.edu.vn Đại diện hỗ trợ Tên Chức danh Mô tả Email Văn Hoàng Kha Cloud Security Engineer, Co-founded and led Viet-AWS Thực thi các hướng kỹ thuật về Bảo mật đám mây và DevSecOps khavan.work@gmail.com Đội ngũ thực hiện dự án Tên Chức danh Mô tả Email Trần Phương Huyền Leader + Backend Dev Quản lý dự án + Phát triển Backend tranphuonghuyen2005@gmail.com Nguyễn Lâm Anh AI Dev Phát triển AI nguyenla110505@gmail.com Nguyễn Văn Linh AI Dev Phát triển AI nguyenvanlinh.1710.it@gmail.com Bùi Nguyễn Tấn Khang Frontend Dev Phát triển Frontend tankhang6a6@gmail.com 6. NGUỒN LỰC VÀ ƯỚC TÍNH CHI PHÍ Định mức đơn giá nhân sự (Đơn giá nhân sự ước tính dựa trên định mức dự án sinh viên/học thuật)\nNguồn lực / Vai trò Trách nhiệm Đơn giá (USD) / Giờ Solution Architects - Thiết kế kiến trúc tổng thể (Hybrid Serverless, RAG Flow).\n- Lựa chọn dịch vụ AWS tối ưu (Bedrock, Lambda, Pinecone).\n- Đảm bảo các yêu cầu phi chức năng (bảo mật, độ trễ, chi phí). 2.3 Software Engineers - Phát triển Frontend (Next.js/Amplify) và tích hợp Cognito.\n- Xây dựng Backend API (Lambda) để xử lý logic người dùng.\n- Quản lý lưu trữ dữ liệu Chat History (DynamoDB). 0.7 AI Engineers - Tinh chỉnh Prompt cho Bedrock để luận giải Tarot/Tử vi.\n- Xây dựng luồng RAG: Chunking tài liệu, Embeddings, Vector Search.\n- Đánh giá độ chính xác và giảm thiểu ảo giác (Hallucination) của AI. 0.7 Ước tính giờ công \u0026amp; chi phí theo giai đoạn (Ước tính nỗ lực cho 3 Iterations - 9 tuần)\nGiai đoạn Dự án Vai trò Giờ công Chi phí (USD) Tổng Chi phí Giai đoạn Iter 3: Design \u0026amp; Prototype\n(Tuần 1-3) Solution Architect\nSoftware Engineer\nAI Engineer 30\n30\n30 $69.0\n$21.0\n$21.0 $111.0 Iter 4: Core Development\n(Tuần 4-6) Solution Architect\nSoftware Engineer\nAI Engineer 20\n80\n80 $46.0\n$56.0\n$56.0 $158.0 Iter 5: Deploy \u0026amp; QA\n(Tuần 7-9) Solution Architect\nSoftware Engineer\nAI Engineer 10\n60\n40 $23.0\n$42.0\n$28.0 $93.0 TỔNG CỘNG 380 $362.0 Phân bổ đóng góp chi phí (Phân bổ trách nhiệm chi phí giữa các bên liên quan)\nBên tham gia Giá trị Đóng góp (USD) Tỷ lệ Đóng góp trên Tổng số Partner (Team) $362.0 97.5% (Chi phí nhân sự tự đóng góp) AWS ~$9.06/tháng 2.5% (Chi phí hạ tầng Cloud ước tính) Customer $0 0% (Dự án học thuật/MVP) 7. NGHIỆM THU Việc nghiệm thu dự án SorcererXStreme sẽ không chỉ dựa trên việc hoàn thành tính năng, mà còn căn cứ vào độ ổn định của hệ thống và chất lượng đầu ra của AI.\n7.1. Gói bàn giao Sản phẩm được coi là sẵn sàng để nghiệm thu khi đội dự án cung cấp đầy đủ các hạng mục sau:\nMã nguồn (Source Code): Repository chứa toàn bộ code Backend (Lambda), Frontend (Next.js), và Infrastructure as Code (Serverless Framework). Tài liệu kỹ thuật (Documentation): Bao gồm SRS, SDS, API Documentation và hướng dẫn triển khai (Deployment Guide). Môi trường vận hành (Live Environment): Đường dẫn (URL) truy cập vào môi trường Demo đã hoạt động ổn định trên AWS. Báo cáo chất lượng (Quality Report): Kết quả kiểm thử (Test Cases) và báo cáo đánh giá độ chính xác của mô hình RAG. 7.2. Quy trình nghiệm thu Quy trình sẽ diễn ra theo trình tự 4 bước:\nTrình diễn (Live Demo): Đội dự án demo trực tiếp các luồng người dùng (User Flow) chính: Đăng ký -\u0026gt; Chọn dịch vụ -\u0026gt; Chat với AI -\u0026gt; Nhận kết quả. Kiểm thử chấp nhận (UAT): Khách hàng/Mentor trực tiếp sử dụng hệ thống (03-05 ngày) để kiểm tra độ chính xác của kiến thức tâm linh và khả năng chịu tải. Phản hồi \u0026amp; Khắc phục: Đội dự án cam kết sửa lỗi nghiêm trọng (Critical) trong 24-48 giờ. Các lỗi nhỏ sẽ được cập nhật trong bản vá sau. Xác nhận hoàn thành: Dự án được nghiệm thu khi không còn lỗi nghiêm trọng và các tính năng cốt lõi hoạt động đúng cam kết. 7.3. Điều kiện từ chối Sản phẩm sẽ chưa được nghiệm thu nếu:\nLỗi triển khai: Hệ thống Downtime hoặc API lỗi \u0026gt; 10%. Sai lệch nội dung: AI đưa ra thông tin sai lệch nghiêm trọng hoặc vi phạm quy tắc an toàn. Vượt ngân sách: Chi phí vận hành thực tế vượt quá ngưỡng cho phép mà không có giải trình hợp lý. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.1-workshop-overview/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "SorcererXtreme AI: Xây dựng Nền tảng Luận giải Dựa trên AI trên AWS Mục đích cốt lõi của dự án này, đối với một workshop dành cho nhà phát triển, là để minh họa cách xây dựng một ứng dụng đa diện, có khả năng mở rộng, tối ưu chi phí, có khả năng xử lý các luồng dữ liệu phức tạp hoàn toàn trong môi trường đám mây.\nVấn đề được giải quyết \u0026amp; Giá trị Kỹ thuật Thách thức: Xây dựng một nền tảng kết hợp nhu cầu tính toán chính xác với sự sáng tạo ngôn ngữ của AI, đồng thời đảm bảo tất cả nội dung đều có thể kiểm chứng và có cơ sở. Các giải pháp dựa trên máy chủ truyền thống thường gặp khó khăn với khả năng mở rộng động cần thiết cho các khối lượng công việc đa dạng như vậy. Giải pháp Kỹ thuật: Chúng tôi giải quyết vấn đề này bằng cách triển khai Lõi Retrieval-Augmented Generation (RAG) sử dụng Amazon Bedrock và Pinecone. Thiết kế này cho phép AI tạo ra các câu trả lời đã được xác minh dựa trên cơ sở kiến thức chuyên biệt, biến hướng dẫn mang tính suy đoán thành những hiểu biết sâu sắc có thể hành động. Điểm nổi bật Kỹ thuật Chính Dự án này đóng vai trò là một nghiên cứu điển hình thiết yếu để tích hợp các dịch vụ AWS quan trọng sau:\nĐiện toán Serverless (phi máy chủ): Chúng tôi sử dụng AWS Lambda làm toàn bộ Backend, loại bỏ chi phí quản lý máy chủ và tối ưu hóa đáng kể chi phí. Triển khai Hiện đại (Lưu trữ Frontend): Triển khai ứng dụng Next.js trên AWS Amplify cung cấp khả năng lưu trữ và CI/CD hợp lý cho Frontend. Luồng Bất đồng bộ Bền vững (Async): Chúng tôi đã xây dựng một hệ thống nhắc nhở tự động đáng tin cậy bằng cách sử dụng EventBridge -\u0026gt; Lambda -\u0026gt; SES. Mô hình này đảm bảo việc gửi hàng loạt tin nhắn mạnh mẽ, có khả năng mở rộng mà không làm quá tải API cốt lõi. Tính bền vững của Dữ liệu và Vector: Chúng tôi quản lý dữ liệu quan hệ phức tạp bên ngoài bằng cách sử dụng NeonDB đồng thời sử dụng Cơ sở dữ liệu Vector chuyên dụng (Pinecone) cho lớp truy xuất RAG tốc độ cao. Bảo mật và DevOps: AWS Parameter Store quản lý tất cả các khóa nhạy cảm và toàn bộ cơ sở hạ tầng được triển khai bằng Serverless Framework được điều khiển bởi GitHub Actions (CI/CD). Bài học Người tham dự sẽ học cách triển khai kiến trúc Microservices hoàn toàn Serverless, giải quyết các thách thức như kết nối cơ sở dữ liệu bên ngoài, phân tách khối lượng công việc đồng bộ/bất đồng bộ và xây dựng giải pháp RAG Core tiết kiệm chi phí.\n"
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.4-ai-development/2.4.1-architecture/",
	"title": "Kiến trúc &amp; Công nghệ",
	"tags": [],
	"description": "",
	"content": "Hệ thống được xây dựng theo kiến trúc Serverless trên AWS để tối ưu hóa chi phí vận hành và khả năng mở rộng.\n1. Stack Công nghệ Chính Thành phần Công nghệ lựa chọn Lý do lựa chọn Ngôn ngữ Python 3.x Hệ sinh thái AI chuyên dụng. Môi trường triển khai tối ưu cho LLM, Embedding và RAG. Compute AWS Lambda Kiến trúc Serverless hướng sự kiện. Tối ưu chi phí vận hành (pay-per-request) và tích hợp liền mạch với hệ sinh thái AWS (S3, API Gateway). Raw Storage Amazon S3 Lưu trữ bền vững \u0026amp; Tối ưu chi phí. Nơi chứa dữ liệu gốc an toàn, tích hợp sẵn sàng với các trigger xử lý tự động của Lambda. Vector DB Pinecone Managed Service. Chuyên dụng cho Vector Search, tốc độ truy vấn cao, độ trễ thấp, không cần quản lý hạ tầng. Meta DB Amazon DynamoDB Độ trễ cực thấp cấp độ mili-giây. Tối ưu cho các truy vấn khớp chính xác (Exact Match) và lưu trữ lịch sử hội thoại với tốc độ phản hồi tức thì. AI Model Amazon Bedrock Unified API. Truy cập đa dạng Foundation Models qua một cổng kết nối duy nhất, đảm bảo tính riêng tư và an toàn dữ liệu tuyệt đối. CI/CD GitHub Actions Automation. Tự động hóa quy trình Test và Deploy code lên Lambda ngay khi push code. 2. Tài nguyên \u0026amp; Môi trường Trước khi đi vào triển khai chi tiết, cần đảm bảo các tài nguyên và quyền truy cập sau đã được thiết lập:\nTài khoản AWS \u0026amp; Region:\nCần một tài khoản AWS đang hoạt động (Active Billing). Tài khoản Dịch vụ bên thứ 3:\nPinecone: Tạo tài khoản và lấy API Key (Serverless Index). GitHub: Cấu hình GitHub Secrets để lưu trữ các credential (AWS_ACCESS_KEY, PINECONE_API_KEY) phục vụ cho CI/CD. Môi trường Local:\nCài đặt AWS CLI v2 và cấu hình aws configure. Cài đặt Python 3.9+ và SAM CLI (Serverless Application Model) để build và deploy Lambda. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "SorcererXtreme: Xây dựng Nền tảng luận giải dựa trên AI trên AWS Tổng quan SorcererXtreme AI là một nền tảng hướng dẫn siêu hình tiên phong, tận dụng AI và kiến trúc Serverless của AWS để cung cấp các bài đọc cá nhân hóa, có cơ sở và đáng tin cậy về Chiêm tinh học, Tarot, Tử vi và Số học.\n1. Phát triển Frontend Phần này tập trung vào việc xây dựng giao diện người dùng React/Next.js và tích hợp với AWS Amplify.\nMục tiêu Công nghệ \u0026amp; Khái niệm Sản phẩm Đầu ra Giao diện \u0026amp; UX Xây dựng các component chính (Chat UI, Profile Settings, Payment Gateways). Giao diện người dùng trực quan, responsive cho các dịch vụ: Tarot Reading, Astrology Chart. Xác thực Tích hợp AWS Cognito và Amplify Authenticator vào Frontend. Hệ thống đăng nhập/đăng ký hoạt động đầy đủ. Tích hợp Backend Viết các hàm Client-side API calls (axios) để gọi đến API Gateway Endpoint (Backend). Các hàm Fetch data/Post requests hoạt động, hiển thị dữ liệu (Response) từ Lambda. 2. Phát triển Backend Đây là phần cốt lõi của kiến trúc Serverless, tập trung vào logic nghiệp vụ và tối ưu hóa hiệu suất.\nMục tiêu Công nghệ \u0026amp; Khái niệm Sản phẩm Đầu ra Lớp API \u0026amp; DB Thiết lập Express.js và serverless-http trên AWS Lambda. Cấu hình Prisma và kết nối an toàn với NeonDB. Các hàm Lambda cơ bản hoạt động: UserAPI (CRUD hồ sơ) và ReminderService. Kiến trúc Asynchronous Xây dựng luồng Reminder Service bằng EventBridge Scheduler và Amazon SES. Logic findUsersToRemind hoạt động và tự động gửi email thông báo. Tối ưu hóa Tối ưu gói triển khai Serverless/Prisma, và thiết lập IAM Roles tối thiểu. Mã nguồn Backend được triển khai tự động qua GitHub Actions (CI/CD). 4. Phát triển AI Phần quan trọng nhất, nơi logic RAG được thiết lập để cung cấp nội dung thông minh.\nMục tiêu Công nghệ \u0026amp; Khái niệm Sản phẩm Đầu ra Lõi RAG Hiểu và thiết lập luồng Retrieval-Augmented Generation (RAG). Kiến trúc RAG hoạt động. Bedrock \u0026amp; Embeddings Sử dụng Amazon Bedrock để tạo Vector Embeddings từ câu hỏi của người dùng và gọi các LLMs. Hàm Lambda (ChatbotAPI) gọi thành công Bedrock để tạo sinh câu trả lời. Truy xuất Dữ liệu Sử dụng Pinecone làm Vector Database để lưu trữ và truy xuất các Chunk kiến thức từ kho tri thức RAG (lưu trữ trong S3). Quá trình tìm kiếm ngữ cảnh (context retrieval) và truyền ngữ cảnh đó vào Prompt để tạo sinh câu trả lời chính xác. Nội dung Tổng quan về Workshop Phát triển Frontend Phát triển Backend Phát triển AI "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.4-ai-development/2.4.2-data-strategy/",
	"title": "Chiến lược dữ liệu",
	"tags": [],
	"description": "",
	"content": "Đây là phần tốn nhiều công sức nghiên cứu nhất để đảm bảo chất lượng câu trả lời của AI (Garbage In, Garbage Out).\n1. Hành trình chuẩn hóa định dạng: Từ JSON sang JSONL Việc lựa chọn định dạng file lưu trữ đóng vai trò quyết định đến hiệu năng xử lý và chi phí bộ nhớ của AWS Lambda. Sau quá trình thử nghiệm, hệ thống quyết định chuẩn hóa toàn bộ dữ liệu Knowledge Base (Tarot, Tử vi, Thần số học) sang định dạng JSONL (.jsonl). Đây là định dạng lưu trữ trong đó mỗi dòng của file là một đối tượng JSON hợp lệ riêng biệt, không phụ thuộc vào nhau. Tại sao chọn JSONL? Tối ưu bộ nhớ: Sử dụng cơ chế Lazy Loading thay vì load toàn bộ file. Giúp mức tiêu thụ RAM của Lambda luôn thấp và ổn định, loại bỏ hoàn toàn lỗi tràn bộ nhớ (OOM) với dataset lớn. Chịu lỗi cục bộ: Lỗi cú pháp ở một dòng không làm \u0026ldquo;gãy\u0026rdquo; toàn bộ pipeline. Hệ thống tự động bỏ qua dòng lỗi và tiếp tục xử lý, đảm bảo tính liên tục của luồng dữ liệu. Tương thích Streaming: Hỗ trợ đọc luồng trực tiếp từ S3, giảm thiểu độ trễ khi bắt đầu xử lý Batch. So sánh với giải pháp cũ (Standard JSON) Định dạng JSON tiêu chuẩn ban đầu đã bộc lộ những điểm yếu chí mạng về hiệu năng:\nĐặc điểm Giải pháp cũ: Standard JSON (.json) Giải pháp hiện tại: JSONL (.jsonl) Cấu trúc - Mảng nguyên khối. - Bao bọc bởi [...], phân cách bằng dấu phẩy. - Dòng độc lập. - Mỗi dòng là một object riêng biệt. Hiệu năng - Memory Hog: Phải load cả file vào RAM để parse DOM. - Memory Safe: Xử lý dòng nào, tốn RAM dòng đó. Rủi ro - Single Point of Failure: Sai 1 dấu phẩy = Hỏng toàn bộ file. - Isolated: Lỗi dòng 1 không ảnh hưởng dòng 2. Minh họa cấu trúc:\nJSON (Cũ - Mảng): [ {\u0026#34;id\u0026#34;: 1, \u0026#34;text\u0026#34;: \u0026#34;Aries...\u0026#34;}, {\u0026#34;id\u0026#34;: 2, \u0026#34;text\u0026#34;: \u0026#34;Taurus...\u0026#34;} ] Hình 2.1: Mẫu dữ liệu dạng json.\nJSONL (Mới - Dòng): {\u0026#34;id\u0026#34;: 1, \u0026#34;text\u0026#34;: \u0026#34;Aries...\u0026#34;} {\u0026#34;id\u0026#34;: 2, \u0026#34;text\u0026#34;: \u0026#34;Taurus...\u0026#34;} Hình 2.2: Cấu hình dữ liệu dạnh jsonl.\n2. Kỹ thuật \u0026ldquo;Chia để trị\u0026rdquo; trong Embedding Thách thức: Dữ liệu thô (Raw text) quá dài và chứa nhiều keyword nhiễu. Khi RAG (Retrieval-Augmented Generation) truy vấn cả đoạn văn lớn, AI dễ bị \u0026ldquo;loãng\u0026rdquo; thông tin và trả lời lan man. Giải pháp: Thay vì embedding cả văn bản, hệ thống thực hiện: Flatten Contexts: Chia nhỏ các trường thông tin trong contexts (ví dụ: uu-diem, nhuoc-diem, tinh-yeu). Meta-Injection: Gắn kèm metadata (Tên, Category, Keyword) vào từng chunk nhỏ trước khi embedding. Kết quả: Khi search vector, hệ thống trích xuất đúng đoạn thông tin cần thiết (ví dụ: chỉ lấy đoạn \u0026ldquo;tình yêu của Bạch Dương\u0026rdquo; thay vì cả bài viết về Bạch Dương), giúp LLM trả lời chính xác trọng tâm. 3. Thiết kế Cơ sở dữ liệu (DynamoDB) Để đảm bảo tốc độ truy xuất dưới 10ms cho các ứng dụng Real-time, hệ thống sử dụng Amazon DynamoDB với thiết kế 2 bảng riêng biệt, phục vụ hai mục đích cốt lõi: Lưu trữ tri thức (Knowledge Base) và Lưu trữ ngữ cảnh hội thoại (Chat History).\nHình 3.1: Danh sách các bảng DynamoDB đang hoạt động.\nBảng Tri thức (MetaphysicalKnowledgeBase) Đây là \u0026ldquo;kho tàng\u0026rdquo; dữ liệu gốc của hệ thống, nơi lưu trữ thông tin chi tiết về Tarot, Các cung hoàng đạo, và Thần số học. Dữ liệu tại đây được dùng làm nguồn tham chiếu chính xác (Ground Truth) cho quá trình RAG.\nPartition Key (PK): category (String). Ví dụ: Tarot_card, Zodiac_sign. Giúp phân nhóm dữ liệu lớn để truy vấn theo loại hình. Sort Key (SK): entity_name (String). Ví dụ: Ace of Cups, Aries. Định danh duy nhất cho từng thực thể trong nhóm. Cấu trúc Item chi tiết: Hệ thống không lưu trữ văn bản phẳng mà lưu dưới dạng cấu trúc JSON trong thuộc tính contexts. Điều này cho phép trích xuất linh hoạt từng khía cạnh (Tình yêu, Sự nghiệp, Sức khỏe) thay vì lấy toàn bộ bài viết.\nHình 3.2: Chi tiết thuộc tính của một lá bài Tarot (Ace of Cups).\nAttribute Name Type Mô tả contexts String (JSON) Chứa các đoạn nội dung đã phân loại (general_upright, love_reversed, v.v.). Đây là nguồn dữ liệu chính để Embedding. keywords List Danh sách từ khóa liên quan, hỗ trợ bổ trợ cho Semantic Search. Bảng Lịch sử Chat (sorcererxtreme-chatMessages) Để AI có thể \u0026ldquo;nhớ\u0026rdquo; được những gì người dùng vừa hỏi (Context Retention), hệ thống cần một bộ nhớ ngắn hạn. Bảng này lưu trữ toàn bộ lịch sử hội thoại theo phiên làm việc.\nPartition Key (PK): sessionId (String). Mã định danh phiên chat của người dùng. Sort Key (SK): timestamp (String). Thời gian gửi tin nhắn (ISO 8601), giúp sắp xếp hội thoại theo đúng trình tự thời gian. Hình 3.3: Mẫu dữ liệu lưu trữ một tin nhắn của người dùng.\nLuồng xử lý: Mỗi khi người dùng gửi tin nhắn mới:\nHệ thống truy vấn bảng này với sessionId hiện tại. Lấy ra $N$ tin nhắn gần nhất (Context Window). Ghép lịch sử này vào Prompt gửi cho LLM để đảm bảo câu trả lời mạch lạc, không bị đứt đoạn ngữ cảnh. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.2-frontend-development/",
	"title": "Phần phát triển Frontend",
	"tags": [],
	"description": "",
	"content": "Xây dựng Frontend Serverless với Next.js \u0026amp; AWS Amplify 1. Tổng quan Workshop Chào mừng bạn đến với Workshop Xây dựng Frontend Serverless hiện đại cho dự án SorcererXtreme.\nTrong dự án này, Frontend đóng vai trò là \u0026ldquo;gương mặt đại diện\u0026rdquo;, nơi người dùng tương tác trực tiếp với các tính năng huyền bí. Nhiệm vụ của chúng ta là xây dựng một giao diện đẹp, mượt mà và giao tiếp hiệu quả với các dịch vụ AWS phía sau.\n2. Kiến trúc Frontend (Frontend Architecture) Chúng ta sẽ tập trung vào kiến trúc của phần Client (Frontend) và các điểm kết nối (Integration Points):\nLuồng hoạt động của Frontend: Hosting \u0026amp; Delivery: Code Next.js được lưu trữ và vận hành trên AWS Amplify. Người dùng truy cập web thông qua mạng lưới CDN toàn cầu (CloudFront) tích hợp sẵn trong Amplify, đảm bảo tốc độ tải trang cực nhanh. Authentication (Xác thực): Khi người dùng Đăng nhập, Frontend sẽ giao tiếp trực tiếp với Amazon Cognito. Cognito trả về một \u0026ldquo;Token\u0026rdquo; (giống như tấm vé thông hành). API Interaction (Giao tiếp): Với mỗi yêu cầu (như chatbot hoặc xem bài Tarot), Frontend sẽ gửi Token kèm theo request đến Amazon API Gateway. Response: Frontend nhận kết quả JSON từ API và hiển thị lên giao diện (Render UI). Frontend không cần biết phía sau API là Database gì hay AI model nào, nó chỉ quan tâm đến đầu vào (Request) và đầu ra (Response). 3. Công nghệ Frontend sử dụng (Tech Stack) Bộ công cụ \u0026ldquo;vũ khí\u0026rdquo; của Frontend Developer trong dự án này:\nCông nghệ Vai trò Tại sao dùng? Next.js (App Router) Framework Hỗ trợ Server-Side Rendering (SSR) tốt cho SEO, Router mạnh mẽ. AWS Amplify (Gen 2) Platform Cung cấp Hosting, CI/CD tự động và thư viện kết nối Cloud cực nhanh. Tailwind CSS Styling Viết CSS nhanh, dễ dàng tùy chỉnh giao diện \u0026ldquo;Dark Mode\u0026rdquo; huyền bí. Framer Motion Animation Tạo hiệu ứng chuyển động mượt mà (như lật bài Tarot 3D). Amplify UI Library Bộ component có sẵn cho phần Đăng nhập/Đăng ký (Login UI). Axios / Fetch HTTP Client Dùng để gọi API Gateway. 4. Thời gian \u0026amp; Chi phí ước tính Mục Chi tiết Thời gian 2-3 giờ mỗi ngày Chi phí ~$9.06/tháng (Toàn bộ dự án) 5. Nội dung thực hành Chúng ta sẽ đi qua quy trình phát triển Frontend chuẩn:\nChuẩn bị môi trường: Thiết lập Next.js và Amplify. UI Implementation: Code giao diện Chat \u0026amp; Tarot với hiệu ứng động. Integration: Tích hợp Login (Cognito) và gọi API (Gateway). CI/CD Pipeline: Đẩy code lên Git và tự động deploy ra Internet. Advanced: Cấu hình tên miền riêng và tối ưu SEO. Backend Reference: Tìm hiểu mô hình RAG. Cleanup: Dọn dẹp tài nguyên. Tư duy Frontend: Trong kiến trúc Serverless, Frontend không chỉ là \u0026ldquo;người hiển thị\u0026rdquo;. Nó còn chịu trách nhiệm về Bảo mật (giữ Token an toàn) và Tối ưu trải nghiệm (xử lý Loading state khi chờ AI trả lời). Hãy chú ý các điểm này trong bài thực hành!\n"
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.3-backend-development/2.3.2-set-up/",
	"title": "Thiết lập môi trường",
	"tags": [],
	"description": "",
	"content": "Bước 1: Khởi tạo Project \u0026amp; Cài đặt Thư viện Tạo thư mục dự án và cài đặt tất cả các dependencies cốt lõi cần thiết.\n# Tạo thư mục chính cho Backend mkdir my-serverless-backend \u0026amp;\u0026amp; cd my-serverless-backend # Khởi tạo gói Node.js npm init -y # Cài đặt Dependencies chính: Express, Prisma Client, Serverless-HTTP, v.v. npm install express cors dotenv @prisma/client axios serverless-http # Cài đặt Dependencies Phát triển: TypeScript, Types cho Node/Express, Prisma CLI, Serverless-Offline npm install -D typescript @types/node @types/express serverless-offline prisma serverless-dotenv-plugin Bước 2: Thiết lập TypeScript \u0026amp; Cấu trúc Thư mục Cấu hình TypeScript và tạo cấu trúc thư mục tiêu chuẩn.\nKhởi tạo tsconfig.json: npx tsc --init Chỉnh sửa tsconfig.json: Mở file tsconfig.json và điều chỉnh các thiết lập sau để đảm bảo mã nguồn Node.js hiện đại và tương thích với Lambda: \u0026quot;target\u0026quot;: \u0026quot;ES2020\u0026quot; (Hoặc mới hơn) \u0026quot;module\u0026quot;: \u0026quot;commonjs\u0026quot; \u0026quot;outDir\u0026quot;: \u0026quot;./dist\u0026quot; (Đầu ra của mã đã biên dịch) \u0026quot;rootDir\u0026quot;: \u0026quot;./src\u0026quot; (Thư mục chứa mã nguồn) \u0026quot;esModuleInterop\u0026quot;: true \u0026quot;strict\u0026quot;: true Tạo Cấu trúc Thư mục: mkdir src src/routes src/services src/controllers Bước 3: Cấu trúc lại Code (Express -\u0026gt; Lambda) Vì Lambda không \u0026ldquo;lắng nghe\u0026rdquo; cổng thông thường, chúng ta dùng serverless-http để đóng gói Express.\nFile src/app.ts (Core Express App):\nimport express from \u0026#39;express\u0026#39;; import cors from \u0026#39;cors\u0026#39;; import routes from \u0026#39;./routes/index\u0026#39;; // Thay đổi thành index nếu bạn dùng routes/index.ts const app = express(); // 1. Middlewares cơ bản app.use(cors({ origin: process.env.FRONTEND_URL || \u0026#39;*\u0026#39; })); app.use(express.json()); // 2. Định tuyến API (Endpoint chính sẽ là /api/...) app.use(\u0026#39;/api\u0026#39;, routes); // QUAN TRỌNG: Không dùng app.listen(), loại bỏ logic web server truyền thống. export default app; File src/handler.ts (Cầu nối Lambda):\nimport serverless from \u0026#34;serverless-http\u0026#34;; import app from \u0026#34;./app\u0026#34;; // Xuất handler chính mà AWS Lambda sẽ gọi export const handler = serverless(app); Bước 4: Cấu hình Prisma \u0026amp; Kết nối NeonDB Để kết nối với NeonDB và đảm bảo Prisma Client hoạt động trên môi trường Linux của AWS Lambda, cần cấu hình binaryTargets.\nTạo File Schema \u0026amp; Cấu hình binaryTargets: npx prisma init Mở file prisma/schema.prisma và thêm cấu hình: generator client {\rprovider = \u0026#34;prisma-client-js\u0026#34;\r// native: Cho máy dev (Mac/Win)\r// rhel-openssl-3.0.x: Cho AWS Lambda (Node 20)\rbinaryTargets = [\u0026#34;native\u0026#34;, \u0026#34;rhel-openssl-3.0.x\u0026#34;] }\rdatasource db {\rprovider = \u0026#34;postgresql\u0026#34;\rurl = env(\u0026#34;DATABASE_URL\u0026#34;)\r}\r// ... model definitions (User, Partner, Reminder, v.v.) Tạo file .env Local: Tạo file .env và dán chuỗi kết nối NeonDB của bạn vào. # Lấy chuỗi kết nối PostgreSQL từ Neon Console DATABASE_URL=\u0026#34;postgresql://[user]:[password]@[endpoint]/[dbname]?sslmode=require\u0026#34; Generate Prisma Client: Chạy lệnh sau để tạo Prisma Client và tải xuống các binary cần thiết. npx prisma generate Hoàn tất: Giờ đây, môi trường local của bạn đã sẵn sàng. Bạn có thể biên dịch code (npm run build) và chạy thử nghiệm cục bộ với serverless-offline.\n"
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.2-frontend-development/2.2.2-ui-implementation/",
	"title": "Xây dựng giao diện người dùng hiện đại",
	"tags": [],
	"description": "",
	"content": "1. Thiết kế Layout (Responsive \u0026amp; Glassmorphism) Mục tiêu của chúng ta là tạo ra một giao diện huyền bí, đậm chất \u0026ldquo;Phù thủy AI\u0026rdquo; như bản Mockup dưới đây:\nSử dụng CSS Grid và Flexbox của Tailwind để tạo layout linh hoạt.\n// src/app/layout.tsx export default function RootLayout({ children }: { children: React.ReactNode }) { return ( \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;body className=\u0026#34;bg-background text-white min-h-screen bg-[url(\u0026#39;/bg-stars.png\u0026#39;)] bg-cover\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;absolute inset-0 bg-black/50\u0026#34; /\u0026gt; {/* Overlay */} \u0026lt;main className=\u0026#34;relative z-10 container mx-auto px-4 py-8 grid grid-cols-1 lg:grid-cols-12 gap-6\u0026#34;\u0026gt; {/* Sidebar chiếm 3 cột trên Desktop */} \u0026lt;aside className=\u0026#34;lg:col-span-3 hidden lg:block\u0026#34;\u0026gt; {/* Sidebar Content */} \u0026lt;/aside\u0026gt; {/* Main Content chiếm 9 cột */} \u0026lt;section className=\u0026#34;lg:col-span-9\u0026#34;\u0026gt; {children} \u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ) } 2. Component: Horoscope Widget Tạo một Widget hiển thị thông tin tử vi hàng ngày với hiệu ứng Glassmorphism.\n// src/components/HoroscopeWidget.tsx import { Star } from \u0026#39;lucide-react\u0026#39;; export default function HoroscopeWidget({ sign, prediction }: { sign: string, prediction: string }) { return ( \u0026lt;div className=\u0026#34;p-6 rounded-2xl bg-white/10 backdrop-blur-lg border border-white/20 hover:bg-white/20 transition-all duration-300 group\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex items-center gap-3 mb-4\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;p-3 rounded-full bg-accent/20 text-accent group-hover:scale-110 transition-transform\u0026#34;\u0026gt; \u0026lt;Star size={24} /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h3 className=\u0026#34;text-xl font-bold\u0026#34;\u0026gt;{sign}\u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;p className=\u0026#34;text-gray-300 leading-relaxed\u0026#34;\u0026gt;{prediction}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ); } 3. Component: Chat Interface Xây dựng giao diện chat với khả năng tự động cuộn và styling tin nhắn động.\n// src/components/ChatBox.tsx import { useEffect, useRef } from \u0026#39;react\u0026#39;; import { clsx } from \u0026#39;clsx\u0026#39;; export default function ChatBox({ messages }: { messages: Message[] }) { const bottomRef = useRef\u0026lt;HTMLDivElement\u0026gt;(null); // Auto-scroll to bottom useEffect(() =\u0026gt; { bottomRef.current?.scrollIntoView({ behavior: \u0026#39;smooth\u0026#39; }); }, [messages]); return ( \u0026lt;div className=\u0026#34;flex flex-col h-[600px] bg-white/5 rounded-xl border border-white/10 overflow-hidden\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;flex-1 overflow-y-auto p-4 space-y-4\u0026#34;\u0026gt; {messages.map((msg, idx) =\u0026gt; ( \u0026lt;div key={idx} className={clsx( \u0026#34;max-w-[80%] p-3 rounded-lg\u0026#34;, msg.role === \u0026#39;user\u0026#39; ? \u0026#34;bg-primary self-end ml-auto\u0026#34; : \u0026#34;bg-white/10 self-start mr-auto\u0026#34; )}\u0026gt; {msg.content} \u0026lt;/div\u0026gt; ))} \u0026lt;div ref={bottomRef} /\u0026gt; \u0026lt;/div\u0026gt; {/* Input Area */} \u0026lt;/div\u0026gt; ); } 4. Animation với Framer Motion Thêm hiệu ứng xuất hiện mượt mà cho các phần tử UI.\nimport { motion } from \u0026#39;framer-motion\u0026#39;; const fadeIn = { hidden: { opacity: 0, y: 20 }, visible: { opacity: 1, y: 0 } }; \u0026lt;motion.div initial=\u0026#34;hidden\u0026#34; animate=\u0026#34;visible\u0026#34; variants={fadeIn} transition={{ duration: 0.5 }} \u0026gt; \u0026lt;HoroscopeWidget sign=\u0026#34;Leo\u0026#34; prediction=\u0026#34;Today is your lucky day!\u0026#34; /\u0026gt; \u0026lt;/motion.div\u0026gt; Chuyện nghề (My Experience) Mobile-First hay Desktop-First? Ban đầu mình thiết kế trên Desktop trước, đến khi mở trên điện thoại thì vỡ layout tùm lum. Bài học: Luôn dùng class hidden lg:block hoặc grid-cols-1 lg:grid-cols-12 để ưu tiên giao diện Mobile trước (mặc định), sau đó mới override cho màn hình lớn. TailwindCSS được sinh ra để làm việc này cực dễ!\nKiểm thử \u0026amp; Xác thực (Verification) Test Case 1: Responsive Design\nMở trình duyệt trên Desktop: Thấy Sidebar bên trái, Chatbox bên phải. Nhấn F12, chuyển sang chế độ Mobile (iPhone 12/14). Kết quả mong đợi: Sidebar ẩn đi, Chatbox tràn màn hình (full width). Test Case 2: Hiệu ứng Hover\nDi chuột vào HoroscopeWidget. Kết quả mong đợi: Nền sáng lên (bg-white/20), icon ngôi sao phóng to nhẹ (scale-110). "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.3-backend-development/2.3.3-configure-serverless/",
	"title": "Cấu hình Serverless Framework",
	"tags": [],
	"description": "",
	"content": "Đây là bước quan trọng nhất, nơi chúng ta định nghĩa hạ tầng AWS (IaC) và tối ưu gói triển khai (deployment package) cho Lambda.\n1. File serverless.yml File cấu hình này bao gồm các phần Bảo mật SSM, Tối ưu Build/Package và IAM Roles cần thiết.\n# serverless.yml org: ten_org_cua_ban service: my-serverless-backend # Đảm bảo service name khớp với thư mục provider: name: aws runtime: nodejs20.x region: ap-southeast-1 timeout: 29 # Tối đa của API Gateway (giữ nguyên) memorySize: 512 # Cấu hình bộ nhớ Lambda (khuyến nghị cho Prisma) # --- Cấu hình Mạng VPC (BẮT BUỘC cho NeonDB) --- # Nếu NeonDB yêu cầu IP cố định hoặc bạn dùng RDS nội bộ, # Lambda cần cấu hình VPC để kết nối ra ngoài hoặc vào VPC. # (Giả định cho NeonDB Public Access, nhưng cần VPC nếu bạn dùng Subnet Private) # vpc: # securityGroupIds: [sg-xxxxxxxx] # subnetIds: [subnet-xxxxxx] # --- Biến Môi trường (Lấy từ SSM) --- environment: # Lấy bí mật từ AWS SSM Parameter Store (Đã được mã hóa) DATABASE_URL: ${ssm:/my-app/${self:provider.stage}/database_url} JWT_SECRET: ${ssm:/my-app/${self:provider.stage}/jwt_secret} FRONTEND_URL: ${ssm:/my-app/${self:provider.stage}/frontend_url, \u0026#39;http://localhost:3000\u0026#39;} # Thêm fallback local PRISMA_CLI_BINARY_TARGETS: rhel-openssl-3.0.x # Quan trọng cho Prisma # --- Cấp quyền IAM (Bắt buộc) --- # Thêm các quyền cần thiết để Lambda đọc SSM và truy cập các dịch vụ khác iam: role: statements: - Effect: \u0026#39;Allow\u0026#39; Action: - \u0026#39;ssm:GetParameter\u0026#39; Resource: \u0026#39;arn:aws:ssm:${self:provider.region}:*:parameter/my-app/${self:provider.stage}/*\u0026#39; # --- Bảo vệ chống DDoS/Spam tiền (Giữ nguyên) --- apiGateway: usagePlan: quota: limit: 5000000 period: MONTH throttle: burstLimit: 200 rateLimit: 100 # --- Tối ưu Dung lượng Gói (Deployment Package) --- build: esbuild: bundle: true minify: true sourcemap: false # Chỉ định rõ những module cần ngoại trừ khỏi gói chính external: - \u0026#39;aws-sdk\u0026#39; - \u0026#39;@prisma/client/runtime/library\u0026#39; package: individually: true patterns: - \u0026#39;src/handler.js\u0026#39; - \u0026#39;src/app.js\u0026#39; - \u0026#39;src/**/*.js\u0026#39; - \u0026#39;dist/**/*.js\u0026#39; # Đảm bảo file JS đã biên dịch được đóng gói - \u0026#39;package.json\u0026#39; - \u0026#39;node_modules/**\u0026#39; # --- Định nghĩa File Binary Prisma (Cực kỳ quan trọng) --- # Chỉ bao gồm file binary Linux cần thiết để gói \u0026lt; 250MB - \u0026#39;node_modules/.prisma/client/libquery_engine-rhel-openssl-3.0.x.so.node\u0026#39; - \u0026#39;node_modules/.prisma/client/schema.prisma\u0026#39; - \u0026#39;!./**\u0026#39; # Xóa tất cả rác sau khi đã định nghĩa các patterns cần thiết ở trên - \u0026#39;!node_modules/aws-sdk/**\u0026#39; # Giảm dung lượng bằng cách loại trừ SDK đã có sẵn trong Lambda plugins: - serverless-offline - serverless-dotenv-plugin functions: api: handler: src/handler.handler events: - http: { path: /, method: ANY } - http: { path: /{proxy+}, method: ANY } 2. Các Bước Cần Thực hiện A. Lưu Bí mật vào AWS SSM (Bảo mật) Trước khi triển khai, bạn phải lưu các giá trị nhạy cảm vào AWS SSM Parameter Store để Serverless Framework có thể đọc chúng.\n# Lệnh lưu DATABASE_URL (SecureString) aws ssm put-parameter \\ --name \u0026#34;/my-app/dev/database_url\u0026#34; \\ --value \u0026#34;postgresql://user:password@endpoint...\u0026#34; \\ --type \u0026#34;SecureString\u0026#34; \\ --overwrite # Lặp lại với JWT_SECRET và FRONTEND_URL B. Chạy Thử nghiệm Cục bộ Sử dụng plugin serverless-offline để chạy API cục bộ, kết nối trực tiếp đến NeonDB thông qua file .env.\n# Chạy API cục bộ trên cổng 3000 (mặc định) sls offline start C. Triển khai Lần đầu Sau khi code đã được kiểm thử cục bộ, bạn sẵn sàng triển khai toàn bộ hạ tầng lên AWS.\n# Triển khai tất cả tài nguyên (Lambda, API Gateway, IAM) sls deploy "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.4-ai-development/2.4.3-storage-retrieval/",
	"title": "Lưu trữ &amp; Truy xuất",
	"tags": [],
	"description": "",
	"content": "Hệ thống sử dụng cơ chế Hybrid Retrieval (kết hợp Vector Search và Key-Value Lookup). Trọng tâm của kiến trúc này là việc sử dụng Pinecone làm bộ não nhớ dài hạn (Long-term Memory) cho AI.\n1. Vector Database: Sức mạnh công nghệ của Pinecone Thay vì tự vận hành hạ tầng, dự án lựa chọn Pinecone - một dịch vụ cơ sở dữ liệu vector chuyên dụng (Managed Vector Database). Đây là thành phần cốt lõi giúp AI \u0026ldquo;hiểu\u0026rdquo; được ngữ nghĩa của các câu hỏi về Tarot hay Tử vi, thay vì chỉ tìm kiếm từ khóa đơn thuần.\nCấu hình Index Dựa trên kiến trúc Serverless, hệ thống sử dụng chế độ Serverless Index của Pinecone để tối ưu chi phí (chỉ trả tiền theo lượng dữ liệu đọc/ghi, không mất phí duy trì server hoạt động).\nHình 3.1: Cấu hình Index thực tế trên Pinecone Console.\nThông số kỹ thuật quan trọng:\nDimensions (Số chiều): 1024. Đây là độ dài của vector. Độ dài này đủ lớn để mã hóa các sắc thái ngữ nghĩa phức tạp của các văn bản huyền học, nhưng vẫn tối ưu hơn so với các model 4096 chiều (quá nặng) hay 768 chiều (có thể thiếu chi tiết). Metric (Thước đo): Cosine Similarity. Hệ thống sử dụng Cosine để đo góc giữa hai vector. Trong không gian ngữ nghĩa, hai vector có góc càng nhỏ (Cosine tiệm cận 1) thì ý nghĩa càng tương đồng. Metric này phù hợp nhất cho các tác vụ NLP (Xử lý ngôn ngữ tự nhiên) so với Euclidean (khoảng cách). Pod Type: Serverless (Tự động scale theo nhu cầu, không cần provision trước). Cấu trúc bản ghi Sức mạnh thực sự của Pinecone nằm ở khả năng kết hợp Vector Search với Metadata Filtering.\nHình 3.2: Chi tiết một bản ghi Vector bao gồm ID, Values và Metadata.\nMỗi bản ghi (Record) được lưu trữ gồm 3 phần:\nID: Định danh duy nhất (Hash từ nội dung gốc) để tránh trùng lặp dữ liệu (Dedup). Values (Vector): Mảng số thực gồm 1024 phần tử, đại diện cho ý nghĩa của đoạn văn bản. Metadata (Siêu dữ liệu): Đây là phần quan trọng nhất giúp tăng độ chính xác (Accuracy). Thay vì tìm trong \u0026ldquo;biển lớn\u0026rdquo;, AI sẽ dùng metadata để khoanh vùng. Ví dụ: Khi user hỏi về \u0026ldquo;Tình yêu của Sư Tử\u0026rdquo;, hệ thống sẽ filter category: \u0026quot;cung-hoang-dao\u0026quot; và entity_name: \u0026quot;Sư Tử\u0026quot; trước, sau đó mới tìm vector gần nhất. Điều này loại bỏ hoàn toàn khả năng AI lấy nhầm thông tin của cung khác. 2. Trade-off Analysis: Tại sao chọn Pinecone thay vì AWS RDS (pgvector)? Trong hệ sinh thái AWS, giải pháp tiêu chuẩn thường là sử dụng Amazon RDS for PostgreSQL cài đặt extension pgvector. Tuy nhiên, sau khi cân nhắc kỹ lưỡng (Trade-off), Pinecone đã được lựa chọn.\nDưới đây là bảng phân tích so sánh chi tiết:\nTiêu chí Pinecone (Managed SaaS) Amazon RDS + pgvector (Self-Managed) Kiến trúc Native Vector DB. Được thiết kế từ lõi chuyên dụng cho lưu trữ và tìm kiếm vector tốc độ cao. Relational DB + Extension. Là database quan hệ truyền thống được \u0026ldquo;gắn thêm\u0026rdquo; khả năng xử lý vector. Vận hành (Ops) Zero Ops. Không cần quản lý server, không cần tinh chỉnh index thủ công. Chỉ cần gọi API. High Ops. Phải quản lý instance, update version, tự cấu hình index (IVFFlat/HNSW), vacuum database định kỳ. Tốc độ (Latency) Cực thấp (\u0026lt;50ms). Tối ưu hóa cho truy vấn vector quy mô lớn. Phụ thuộc vào cấu hình phần cứng (CPU/RAM) và cách tuning index. Dễ bị chậm khi dữ liệu lớn nếu không tối ưu tốt. Chi phí (Cost) Pay-as-you-go. Tính tiền dựa trên số lượng vector lưu trữ và số lần đọc/ghi. Rất rẻ khi khởi đầu dự án. Chi phí cố định (Hourly). Phải trả tiền thuê instance chạy 24/7 ngay cả khi không có ai dùng (trừ khi dùng Aurora Serverless v2 nhưng giá khá cao). Khả năng lọc (Filtering) Pre-filtering Native. Hỗ trợ lọc metadata trước khi tìm kiếm vector (Single-stage filtering) rất mạnh mẽ. Phải kết hợp câu lệnh SQL WHERE với vector search, đôi khi ảnh hưởng đến hiệu năng nếu index không chuẩn. Kết luận: Với quy mô dự án hiện tại và yêu cầu triển khai nhanh (Time-to-market), Pinecone là lựa chọn tối ưu nhờ tính chất Serverless, giúp đội ngũ tập trung vào phát triển tính năng AI thay vì tốn thời gian quản trị Database (DBA tasks).\n3. Tại sao lại cần thêm DynamoDB? Mặc dù Pinecone rất mạnh về tìm kiếm ngữ nghĩa (Semantic Search), nhưng hệ thống vẫn cần DynamoDB vì:\nTruy xuất định danh (Exact Match): Lambda Metaphysical cần lấy thông tin chính xác tuyệt đối dựa trên ID (ví dụ: Ý nghĩa lá bài \u0026ldquo;The Fool\u0026rdquo; khi rút bài, hoặc thông tin sao \u0026ldquo;Tử Vi\u0026rdquo;). DynamoDB làm việc này nhanh và rẻ hơn vector search. Tăng tốc độ (Latency): Giảm tải cho Vector DB ở các tác vụ không cần AI suy luận. Lưu trữ Dataset gốc: Dùng làm nguồn backup và tra cứu nhanh metadata mà không cần decode vector. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.3-backend-development/",
	"title": "Phần phát triển Backend",
	"tags": [],
	"description": "",
	"content": "Xây dựng và Tự động hóa với Backend Serverless (Serverless V4) Bài hướng dẫn này là tài liệu tổng hợp, chi tiết toàn bộ quy trình phát triển Backend cho dự án SorcererXtreme AI, từ việc thiết lập môi trường phát triển cục bộ cho đến khi hoàn thành quy trình triển khai tự động (CI/CD) lên AWS.\n1. Bối cảnh \u0026amp; Thách thức Kỹ thuật Trong quá trình phát triển các ứng dụng Serverless hiệu suất cao, chúng ta phải đối mặt với nhiều rào cản kỹ thuật phức tạp:\nChuyển đổi Framework: Việc chuyển đổi từ Framework HTTP truyền thống như Express.js sang môi trường phi kết nối (stateless) của AWS Lambda đòi hỏi sử dụng serverless-http và thay đổi cấu trúc mã nguồn. Quản lý Cơ sở dữ liệu: Sử dụng ORM phức tạp như Prisma trên nền tảng Serverless yêu cầu kỹ thuật tối ưu hóa gói triển khai (deployment package size) dưới 250MB và phải tải đúng Prisma Binary (rhel-openssl-3.0.x) cho môi trường Linux của Lambda. Bảo mật: Đảm bảo các chuỗi kết nối nhạy cảm không bao giờ được lưu trữ trong mã nguồn, mà phải được quản lý an toàn bằng AWS SSM Parameter Store. 2. Giá trị Cốt lõi của Kiến trúc Được xây dựng Kiến trúc Backend của chúng ta được thiết kế để giải quyết những thách thức trên, mang lại các lợi ích then chốt:\nTối ưu hóa Chi phí và Hiệu suất: Sử dụng AWS Lambda và Serverless Framework V4 đảm bảo bạn chỉ trả tiền cho thời gian code thực sự chạy. Việc tối ưu hóa gói Prisma giúp giảm đáng kể thời gian khởi động (Cold Start). Tự động hóa hoàn toàn (CI/CD): Xây dựng quy trình GitHub Actions giúp tự động hóa toàn bộ vòng lặp phát triển: Code -\u0026gt; Push -\u0026gt; Build -\u0026gt; Deploy, loại bỏ hoàn toàn các bước triển khai thủ công và giảm thiểu lỗi do con người. Tính linh hoạt Dữ liệu: Thiết lập kết nối ổn định và an toàn với Database bên ngoài AWS , minh chứng cho khả năng tích hợp linh hoạt trong các dự án thực tế. Bài hướng dẫn này sẽ là bản đồ chi tiết từng bước, giúp bạn làm chủ toàn bộ quy trình phát triển Backend Serverless hiện đại.\nChuẩn bị Thiết lập môi trường Cấu hình Serverless Framework Lưu khóa bảo mật Tự động hóa CI/CD Kết nối microservices Thiết lập email Tổng kết quy trình phát triển "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.2-frontend-development/2.2.3-integration/",
	"title": "Tích hợp API Gateway &amp; Authentication",
	"tags": [],
	"description": "",
	"content": "1. Luồng xác thực (Authentication Flow) Trước khi đi vào code, hãy hiểu cách Frontend giao tiếp với Cognito và API Gateway:\nUser nhập User/Pass. Cognito trả về JWT Token (ID Token, Access Token). Frontend gửi Request kèm Token trong Header Authorization. API Gateway xác thực Token. Nếu hợp lệ -\u0026gt; Chuyển tiếp cho Lambda. 2. Cấu hình AWS Amplify Cài đặt thư viện aws-amplify để kết nối Frontend với các dịch vụ AWS:\nnpm install aws-amplify @aws-amplify/ui-react Cấu hình trong src/app/layout.tsx:\n\u0026#39;use client\u0026#39;; import { Amplify } from \u0026#39;aws-amplify\u0026#39;; import config from \u0026#39;@/amplifyconfiguration.json\u0026#39;; Amplify.configure(config); 3. Tích hợp Amazon Cognito (Authentication) Sử dụng Authenticator component để tạo luồng đăng nhập/đăng ký bảo mật:\nimport { Authenticator } from \u0026#39;@aws-amplify/ui-react\u0026#39;; export default function LoginPage() { return ( \u0026lt;Authenticator\u0026gt; {({ signOut, user }) =\u0026gt; ( \u0026lt;main\u0026gt; \u0026lt;h1\u0026gt;Xin chào, {user?.username}\u0026lt;/h1\u0026gt; \u0026lt;button onClick={signOut}\u0026gt;Đăng xuất\u0026lt;/button\u0026gt; \u0026lt;/main\u0026gt; )} \u0026lt;/Authenticator\u0026gt; ); } 4. Custom Hook: useAuth (Best Practices) Thay vì gọi trực tiếp fetchAuthSession ở khắp nơi, hãy tạo một Custom Hook để tái sử dụng logic xác thực và lấy Token.\n// src/hooks/useAuth.ts import { fetchAuthSession } from \u0026#39;aws-amplify/auth\u0026#39;; import { useState, useEffect } from \u0026#39;react\u0026#39;; export function useAuth() { const [token, setToken] = useState\u0026lt;string | null\u0026gt;(null); useEffect(() =\u0026gt; { const getToken = async () =\u0026gt; { try { const session = await fetchAuthSession(); setToken(session.tokens?.idToken?.toString() || null); } catch (err) { console.error(\u0026#34;Error fetching auth session\u0026#34;, err); } }; getToken(); }, []); return { token }; } 5. Gọi API với Error Handling Xử lý lỗi chuyên nghiệp bằng try/catch/finally và hiển thị thông báo cho người dùng.\n// src/services/api.ts export const chatWithAI = async (message: string, token: string) =\u0026gt; { try { const response = await fetch(`${process.env.NEXT_PUBLIC_API_URL}/chat`, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: `Bearer ${token}` }, body: JSON.stringify({ message }) }); if (!response.ok) { if (response.status === 401) throw new Error(\u0026#34;Phiên đăng nhập hết hạn\u0026#34;); if (response.status === 429) throw new Error(\u0026#34;Bạn gửi tin nhắn quá nhanh\u0026#34;); throw new Error(\u0026#34;Lỗi hệ thống\u0026#34;); } return await response.json(); } catch (error) { console.error(\u0026#34;API Error:\u0026#34;, error); throw error; // Ném lỗi ra để UI xử lý hiển thị } }; Chuyện nghề (My Experience) Đừng bao giờ lộ API Key! Có lần mình lỡ commit file .env chứa API Key lên GitHub. Hậu quả là AWS gửi mail cảnh báo ngay lập tức. Giải pháp: Luôn thêm .env vào .gitignore. Với Amplify, file amplifyconfiguration.json an toàn để public vì nó chỉ chứa ID của các resource (như User Pool ID), không chứa Secret Key.\nKiểm thử \u0026amp; Xác thực (Verification) Test Case 1: Đăng nhập thành công\nVào trang Login, nhập User/Pass đã tạo. Nhấn Sign In. Kết quả mong đợi: Chuyển hướng vào trang chính, hiển thị \u0026ldquo;Xin chào, [Username]\u0026rdquo;. Test Case 2: Kiểm tra Token\nMở DevTools (F12) -\u0026gt; Network Tab. Gửi một tin nhắn Chat. Tìm request gửi đến API Gateway. Kiểm tra Header: Phải có dòng Authorization: Bearer eyJra... (JWT Token). "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.4-ai-development/2.4.4-models-rag/",
	"title": "AI Models &amp; RAG Pipeline",
	"tags": [],
	"description": "",
	"content": "Hệ thống sử dụng Amazon Bedrock làm cổng kết nối tập trung (Unified API), giúp đơn giản hóa việc quản lý version và bảo mật credentials.\n1. Phân tích lựa chọn Model Embedding: Cohere Embed Multilingual v3 ID: cohere.embed-multilingual-v3 Tại sao là Cohere mà không phải Titan? Xử lý tiếng Việt/Hán-Việt: Cohere v3 được huấn luyện trên tập dữ liệu đa ngôn ngữ lớn, hiểu tốt các từ ngữ Hán-Việt đặc thù trong huyền học (như \u0026ldquo;Thien Di\u0026rdquo;, \u0026ldquo;Phu The\u0026rdquo;) mà các model phương Tây thường hiểu sai. Input Type: Hỗ trợ tham số input_type=\u0026quot;search_query\u0026quot; (cho câu hỏi user) và \u0026quot;search_document\u0026quot; (cho database), giúp tối ưu hóa không gian vector cho việc tìm kiếm. Dimension: 1024 chiều - Đây là điểm ngọt (sweet spot) cân bằng giữa độ chính xác ngữ nghĩa và chi phí lưu trữ trên Pinecone. Generative LLM: Amazon Nova Pro ID: amazon.nova-pro-v1:0 Sức mạnh suy luận (Reasoning): Thay vì chỉ tóm tắt văn bản, Nova Pro có khả năng xâu chuỗi logic. Ví dụ: Từ 3 lá bài Tarot rời rạc (Quá khứ - Hiện tại - Tương lai), model có thể liên kết chúng thành một câu chuyện nhân quả mạch lạc. Cấu hình tham số (Inference Config): temperature: 0.3: Giữ ở mức thấp để AI bám sát vào Knowledge Base, tránh \u0026ldquo;sáng tạo\u0026rdquo; ra các kiến thức sai lệch (Hallucination). topP: 0.9: Cho phép một chút linh hoạt trong cách diễn đạt để lời khuyên nghe tự nhiên, giống người hơn. 2. Triển khai trên AWS Lambda Dưới đây là đoạn code mẫu Python (boto3) được sử dụng trong Lambda Function để thực hiện luồng RAG: Embed câu hỏi -\u0026gt; (Search Pinecone) -\u0026gt; Gửi Prompt cho Nova Pro.\nimport boto3 import json import os # Khởi tạo Bedrock Runtime client bedrock = boto3.client( service_name=\u0026#39;bedrock-runtime\u0026#39;, region_name=\u0026#39;us-east-1\u0026#39; ) def generate_embedding(text): \u0026#34;\u0026#34;\u0026#34; Bước 1: Chuyển đổi câu hỏi người dùng thành Vector \u0026#34;\u0026#34;\u0026#34; response = bedrock.invoke_model( modelId=\u0026#39;cohere.embed-multilingual-v3\u0026#39;, contentType=\u0026#39;application/json\u0026#39;, accept=\u0026#39;application/json\u0026#39;, body=json.dumps({ \u0026#34;texts\u0026#34;: [text], \u0026#34;input_type\u0026#34;: \u0026#34;search_query\u0026#34; # Tối ưu cho query }) ) result = json.loads(response[\u0026#39;body\u0026#39;].read()) return result[\u0026#39;embeddings\u0026#39;][0] def query_llm(context_chunk, user_question, history): \u0026#34;\u0026#34;\u0026#34; Bước 2: Gửi Context + Câu hỏi cho Amazon Nova Pro \u0026#34;\u0026#34;\u0026#34; # System Prompt: Định hình nhân cách chuyên gia system_prompt = \u0026#34;\u0026#34;\u0026#34;Bạn là một chuyên gia Tarot và Chiêm tinh học tận tâm. Hãy trả lời câu hỏi dựa trên thông tin được cung cấp trong thẻ \u0026lt;context\u0026gt;. Nếu thông tin không đủ, hãy thành thật nói rằng bạn không biết, đừng tự bịa ra.\u0026#34;\u0026#34;\u0026#34; # Construct Message Payload (Nova Pro structure) prompt_payload = { \u0026#34;system\u0026#34;: [{\u0026#34;text\u0026#34;: system_prompt}], \u0026#34;messages\u0026#34;: [ # Có thể chèn lịch sử chat vào đây {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [{\u0026#34;text\u0026#34;: f\u0026#34;Context: {context_chunk}\\n\\nQuestion: {user_question}\u0026#34;}]} ], \u0026#34;inferenceConfig\u0026#34;: { \u0026#34;temperature\u0026#34;: 0.3, # Giảm ảo giác \u0026#34;maxTokens\u0026#34;: 1000 } } response = bedrock.invoke_model( modelId=\u0026#39;amazon.nova-pro-v1:0\u0026#39;, body=json.dumps(prompt_payload) ) result = json.loads(response[\u0026#39;body\u0026#39;].read()) return result[\u0026#39;output\u0026#39;][\u0026#39;message\u0026#39;][\u0026#39;content\u0026#39;][0][\u0026#39;text\u0026#39;] "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.4-ai-development/",
	"title": "Phần phát triển AI",
	"tags": [],
	"description": "",
	"content": "1. Giới thiệu Tài liệu này là một Technical Case Study mô tả quy trình xây dựng hệ thống AI tư vấn đa lĩnh vực (Tarot, Thần số học, Tử vi, Chiêm tinh) dựa trên kiến trúc Serverless. Mục tiêu cốt lõi là giải quyết bài toán \u0026ldquo;ảo giác\u0026rdquo; của AI thông qua luồng RAG (Retrieval-Augmented Generation) chặt chẽ, đảm bảo câu trả lời luôn bám sát Knowledge Base đã được kiểm chứng.\nĐặt vấn đề: Thách thức của AI trong lĩnh vực Huyền học Xây dựng AI cho lĩnh vực huyền học đặt ra những rào cản kỹ thuật đặc thù mà các giải pháp chatbot thông thường khó đáp ứng:\nTính trừu tượng và Đa nghĩa: Dữ liệu chứa nhiều thuật ngữ Hán-Việt và khái niệm trừu tượng (ví dụ: ý nghĩa lá bài thay đổi theo vị trí trải, sao chiếu mệnh thay đổi theo giờ sinh). Các LLM phổ quát thường gặp khó khăn trong việc nắm bắt ngữ cảnh hẹp này. Yêu cầu độ chính xác tuyệt đối: Người dùng tìm kiếm lời khuyên cần sự chính xác. Việc AI tự \u0026ldquo;bịa\u0026rdquo; kiến thức (như sai vị trí sao, sai ý nghĩa số) là rủi ro nghiêm trọng nhất cần loại bỏ. Xử lý dữ liệu phi cấu trúc: Knowledge Base đầu vào không đồng nhất, đòi hỏi quy trình chuẩn hóa (ETL) phức tạp để chuyển đổi thành Vector Embedding mà không làm mất đi ngữ nghĩa gốc. Chiến lược Tối ưu Chi phí Một trong những ưu tiên hàng đầu của dự án là tối ưu hóa chi phí vận hành ngay từ ngày đầu tiên. Thay vì duy trì các cụm server tốn kém 24/7, hệ thống áp dụng triệt để mô hình Pay-as-you-go.\nKiến trúc này giúp giảm thiểu rủi ro tài chính cho giai đoạn MVP (Minimum Viable Product), khi lượng người dùng chưa ổn định. Dưới đây là bảng phân tích chi phí đơn vị cho các dịch vụ chính:\nDịch vụ Vai trò Mô hình tính phí Đơn giá ước tính AWS Lambda Xử lý logic Backend Theo số lần request \u0026amp; thời gian chạy ~$0.20 / 1 triệu requests Pinecone Serverless Vector Database (Lưu trữ) Theo dung lượng lưu trữ \u0026amp; Read Units ~$0.33 / GB / tháng Amazon Bedrock LLM Inference (Nova Pro) Theo Input/Output Tokens Input: ~$0.0008 / 1k tokens\nOutput: ~$0.0032 / 1k tokens Cohere Embed Embedding Model (Multilingual) Theo số tokens đã xử lý ~$0.10 / 1 triệu tokens DynamoDB Metadata \u0026amp; Cache Write/Read Capacity Units (On-demand) ~$1.25 / 1 triệu Write Units Nhận định: Với kiến trúc này, chi phí duy trì hệ thống khi không có người dùng (Idle state) gần như bằng 0.\n2. Sơ đồ kiến trúc mảng AI Nội dung chi tiết Kiến trúc hệ thống Chiến lược dữ liệu Lưu trữ \u0026amp; Truy xuất Mô hình AI \u0026amp; RAG CI/CD \u0026amp; Testing Bài học \u0026amp; Roadmap "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.3-backend-development/2.3.4-aws-ssm/",
	"title": "Quản lí khóa bí mật",
	"tags": [],
	"description": "",
	"content": "Việc lưu trữ các biến môi trường nhạy cảm (DATABASE_URL, JWT_SECRET) vào AWS Systems Manager (SSM) Parameter Store là tiêu chuẩn về bảo mật cho các ứng dụng Serverless.\n1. Chuẩn bị Trong serverless.yml của bạn, bạn đã sử dụng biến ${self:provider.stage} (mặc định là dev nếu không chỉ định). Để thống nhất với cấu hình đó, chúng ta nên định nghĩa Key theo format /my-app/\u0026lt;stage\u0026gt;/\u0026lt;key\u0026gt;.\n2. Chạy Lệnh CLI để Lưu Key Bạn cần chạy các lệnh này qua AWS CLI sau khi đã cấu hình quyền truy cập.\n# LƯU Ý: Thay thế \u0026lt;YOUR_VALUE\u0026gt; bằng giá trị thực tế của bạn. # Chúng ta sẽ sử dụng stage mặc định là \u0026#34;dev\u0026#34; cho môi trường workshop. # --- 1. Lưu Connection String của NeonDB --- # Dùng \u0026#34;SecureString\u0026#34; để mã hóa dữ liệu. aws ssm put-parameter \\ --name \u0026#34;/my-app/dev/database_url\u0026#34; \\ --value \u0026#34;postgresql://user:pass@ep-xyz.aws.neon.tech/neondb?sslmode=require\u0026#34; \\ --type \u0026#34;SecureString\u0026#34; \\ --overwrite # --- 2. Lưu JWT Secret --- aws ssm put-parameter \\ --name \u0026#34;/my-app/dev/jwt_secret\u0026#34; \\ --value \u0026#34;a_very_long_and_secure_jwt_key_314159\u0026#34; \\ --type \u0026#34;SecureString\u0026#34; \\ --overwrite # --- 3. Lưu Frontend URL (Nếu cần thiết cho CORS) --- aws ssm put-parameter \\ --name \u0026#34;/my-app/dev/frontend_url\u0026#34; \\ --value \u0026#34;https://your-amplify-app.amplifyapp.com\u0026#34; \\ --type \u0026#34;String\u0026#34; \\ --overwrite 3. Kiểm tra Sau khi lưu, bạn có thể chạy lệnh sau để kiểm tra xem Parameter đã được lưu đúng chưa và Serverless Framework có thể truy cập được không:\n# Lệnh kiểm tra và giải mã giá trị (cần quyền SSM Read) aws ssm get-parameter \\ --name \u0026#34;/my-app/dev/database_url\u0026#34; \\ --with-decryption Ghi chú Quan trọng: Trong serverless.yml, bạn đã định nghĩa: DATABASE_URL: ${ssm:/my-app/prod/database_url}. Để đồng bộ với lệnh trên, bạn cần sửa prod thành dev trong serverless.yml nếu bạn triển khai với stage mặc định, hoặc chạy lệnh CLI với stage prod nếu bạn muốn giữ nguyên file serverless.yml.\n"
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.2-frontend-development/2.2.4-deployment/",
	"title": "Thiết lập CI/CD Pipeline với AWS Amplify",
	"tags": [],
	"description": "",
	"content": "1. Quy trình CI/CD Chúng ta sẽ thiết lập một quy trình tự động hóa hoàn toàn như sau:\nSource: Developer push code lên GitHub. Build: Amplify tự động phát hiện thay đổi, cài đặt dependencies và build Next.js. Deploy: Đẩy code đã build lên hệ thống Hosting toàn cầu. Verify: Kiểm tra trang web hoạt động (Health Check). 2. Kết nối Repository Đẩy code lên Git Repository (GitHub/GitLab/CodeCommit). Trong AWS Amplify Console, chọn Host web app. Kết nối với Repository chứa mã nguồn Frontend. 3. Cấu hình Build (Build Specification) Amplify sử dụng file amplify.yml để định nghĩa các bước build.\nversion: 1 frontend: phases: preBuild: commands: - npm ci build: commands: - npm run build artifacts: baseDirectory: .next files: - \u0026#39;**/*\u0026#39; cache: paths: - node_modules/**/* 4. Quản lý Biến môi trường (Environment Variables) Không bao giờ hard-code các giá trị nhạy cảm hoặc thay đổi theo môi trường (như API URL) trong code. Hãy sử dụng Environment Variables trong Amplify.\nVào App settings \u0026gt; Environment variables. Thêm biến: Key: NEXT_PUBLIC_API_URL Value: https://xyz.execute-api.us-east-1.amazonaws.com/prod Trong code Next.js, truy cập bằng process.env.NEXT_PUBLIC_API_URL. Lưu ý: Các biến bắt đầu bằng NEXT_PUBLIC_ sẽ được Next.js nhúng vào code Frontend tại thời điểm build.\n5. Branch Previews (Pull Request Previews) Tính năng này cực kỳ hữu ích khi làm việc nhóm.\nKhi bạn tạo một Pull Request (PR) trên GitHub, Amplify sẽ tự động tạo một môi trường Preview tạm thời (có URL riêng). Team Leader có thể vào URL đó để review tính năng mới trước khi Merge vào nhánh chính. Sau khi Merge, môi trường Preview sẽ tự động bị xóa. Để bật tính năng này: Vào App settings \u0026gt; Previews \u0026gt; Enable previews.\nChuyện nghề (My Experience) Lỗi Build trên Linux vs Windows Máy mình dùng Windows (không phân biệt hoa thường), nhưng Amplify chạy Linux (có phân biệt). Có lần mình import Component.tsx nhưng file lại tên là component.tsx. Ở máy mình chạy ngon ơ, lên Amplify thì lỗi \u0026ldquo;File not found\u0026rdquo;. Bài học: Luôn đặt tên file chuẩn (PascalCase cho Component, camelCase cho ultils) và kiểm tra kỹ khi đổi tên file.\nKiểm thử \u0026amp; Xác thực (Verification) Test Case 1: Trigger Build\nSửa một dòng text nhỏ trong file page.tsx. Commit và Push lên GitHub: git push origin main. Vào Amplify Console. Kết quả mong đợi: Thấy trạng thái chuyển sang \u0026ldquo;Provisioning\u0026rdquo; -\u0026gt; \u0026ldquo;Building\u0026rdquo; -\u0026gt; \u0026ldquo;Deploying\u0026rdquo;. Test Case 2: Kiểm tra Log\nClick vào lần build đang chạy. Mở tab Frontend. Kết quả mong đợi: Thấy log xanh (Success) ở các bước. 2024-05-20T10:00:00.000Z [INFO]: # Executing command: npm run build\r...\r2024-05-20T10:01:00.000Z [INFO]: Compiled successfully "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.4-ai-development/2.4.5-cicd/",
	"title": "CI/CD &amp; Testing",
	"tags": [],
	"description": "",
	"content": "Hệ thống áp dụng quy trình CI/CD tự động hóa hoàn toàn thông qua GitHub Actions, đảm bảo code luôn được kiểm tra (Test) trước khi triển khai (Deploy) lên môi trường AWS Lambda.\n1. Cơ chế CI – Continuous Integration Mỗi khi có code mới được đẩy lên (Push) hoặc tạo Pull Request vào nhánh main, quy trình CI sẽ tự động kích hoạt để đảm bảo tính toàn vẹn của logic.\nLuồng xử lý: [Code Commit] ➔ [GitHub Actions Trigger] ➔ [Runner Ubuntu Start] ➔ [Setup Python Env] ➔ [Run Pytest] ➔ [Result: ✅ Pass / ❌ Fail]\nMocking Strategy: Toàn bộ Unit Test sử dụng thư viện unittest.mock để giả lập các dịch vụ AWS (S3, DynamoDB, Bedrock). Điều này giúp: Zero Cost: Chạy test không tốn phí gọi API AWS. High Speed: Test chạy trong vài giây thay vì chờ phản hồi mạng. Safety: Không bao giờ ghi đè hay xóa dữ liệu thật trên Production. 2. Cơ chế CD – Continuous Deployment Chỉ khi quy trình CI trả về kết quả Success (✅), luồng CD mới được kích hoạt để đóng gói và đẩy code lên AWS.\nLuồng xử lý: [CI Success] ➔ [Install Binary Libs] ➔ [Package Zip 📦] ➔ [AWS CLI Upload 🚀] ➔ [Lambda Live Update]\nLưu ý về Gói Deploy (Deployment Package): Một thách thức lớn với AWS Lambda là sự tương thích của các thư viện C-extension (như numpy trong xử lý tính toán). Hệ thống giải quyết bằng cách cài đặt và build thư viện với flag --platform manylinux2014_x86_64 ngay trong quy trình CD để đảm bảo tương thích tuyệt đối với môi trường Amazon Linux của Lambda.\n3. Chiến lược Unit Testing Hệ thống kiểm thử bao phủ 3 lớp logic: Input Validation, Happy Path (Luồng chạy đúng), và Error Handling (Xử lý lỗi).\nChatbot Lambda (sorcererxstreme-chatbot) Input Validation: Case 1 (Missing Session): Gửi thiếu sessionId → Trả về 400 Bad Request. Case 2 (Missing Question): Gửi thiếu nội dung câu hỏi → Trả về 400. Case 3 (Invalid JSON): Body không đúng định dạng JSON → Trả về lỗi Parse Error. Happy Path: Case 4: Giả lập luồng RAG đầy đủ: Load History → Query Pinecone → Call Bedrock → Save Chat. Đảm bảo AI trả về phản hồi 200 OK. Embedding Lambda (sorcererxstreme-embedding) Logic \u0026amp; Utilities: Case 1 (Flatten Contexts): Kiểm tra hàm làm phẳng JSON. Input {\u0026quot;hobbies\u0026quot;: [\u0026quot;code\u0026quot;, \u0026quot;read\u0026quot;]} phải thành chuỗi \u0026quot;hobbies: code, read\u0026quot;. Case 2 (Bedrock Fail): Giả lập Bedrock bị lỗi mạng. Hàm get_embedding phải trả về None để không làm sập luồng Batch. Integration Flow: Case 3 (Happy Flow): Giả lập đọc file JSONL từ S3 → Embed 2 items → Ghi vào DynamoDB \u0026amp; Pinecone. Kiểm tra số lần gọi API phải khớp với số items. Case 4 (S3 Error): Giả lập không tìm thấy file S3 → Hệ thống báo lỗi 500 (Internal Error). Metaphysical Lambda (sorcererxstreme-metaphysical) Đây là function phức tạp nhất với logic rẽ nhánh theo Domain.\nInput Validation: Case 1 (Invalid Domain): Gửi domain: \u0026quot;bitcoin\u0026quot; → Trả về 400 (Chỉ hỗ trợ Tarot, Horoscope, Numerology, Astrology). Case 2 (Missing Context): Chọn \u0026ldquo;Tử Vi\u0026rdquo; nhưng thiếu birth_date → Trả về yêu cầu nhập liệu. Case 3 (Empty Tarot): Chọn \u0026ldquo;Tarot\u0026rdquo; nhưng mảng cards_drawn rỗng → Cảnh báo chọn bài. Domain Logic: Case 4 (Tarot Flow): Mock DynamoDB trả về ý nghĩa lá bài \u0026ldquo;The Sun\u0026rdquo;. Kiểm tra AI có nhận được đúng context để phân tích không. Case 5 (Horoscope Flow): Kiểm tra tích hợp thư viện lasotuvi. Mock object \u0026ldquo;Thiên Bàn\u0026rdquo; để đảm bảo AI nhận được thông tin \u0026ldquo;Mệnh: Lộ Bàng Thổ\u0026rdquo;. Case 6 (Graceful Degradation): Khi Bedrock quá tải (Throttling), hệ thống trả về thông báo thân thiện thay vì crash. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.2-frontend-development/2.2.5-advanced-deployment/",
	"title": "Tối ưu hóa &amp; Triển khai Nâng cao",
	"tags": [],
	"description": "",
	"content": "Sau khi đã deploy thành công ứng dụng SorcererXtreme lên môi trường Internet, công việc của chúng ta chưa dừng lại. Để sản phẩm thực sự \u0026ldquo;Production-Ready\u0026rdquo;, chúng ta cần thực hiện các bước tinh chỉnh chuyên sâu.\n1. Tên miền riêng (Custom Domain) Mặc định, AWS Amplify cung cấp một đường dẫn khá dài và khó nhớ (ví dụ: main.d12345.amplifyapp.com). Việc thiết lập tên miền riêng không chỉ giúp ứng dụng chuyên nghiệp hơn mà còn cải thiện độ tin cậy.\nQuy trình thực hiện:\nMua tên miền: Bạn có thể mua trực tiếp trên Amazon Route 53 hoặc các nhà cung cấp khác (Namecheap, GoDaddy). Cấu hình trong Amplify: Vào App settings \u0026gt; Domain management. Nhấn Add domain và nhập tên miền của bạn (ví dụ: sorcererxtreme.vn). Xác thực DNS: Nếu mua trên Route 53: Amplify tự động cấu hình (Zero-config). Nếu mua bên ngoài: Amplify sẽ cung cấp bản ghi CNAME để bạn thêm vào trang quản lý DNS của nhà cung cấp. SSL/TLS: Amplify sẽ tự động cấp phát và quản lý chứng chỉ SSL miễn phí, đảm bảo ổ khóa xanh (HTTPS) cho website. 2. Quản lý Biến môi trường (Environment Variables) Trong quá trình phát triển, chúng ta thường dùng file .env.local để chứa các Key nhạy cảm. Tuy nhiên khi deploy, các file này không được đẩy lên Git.\nTại sao quan trọng?\nBảo mật: Giấu kín các khóa API (như API Gateway Endpoint, Cognito User Pool ID) khỏi mã nguồn công khai. Linh hoạt: Dễ dàng thay đổi cấu hình giữa môi trường Staging và Production mà không cần sửa code. Cách thiết lập:\nTruy cập Amplify Console \u0026gt; Chọn App \u0026gt; Environment variables. Nhập các Key tương ứng (ví dụ: NEXT_PUBLIC_API_URL, NEXT_PUBLIC_USER_POOL_ID). Trigger lại quá trình Build để biến môi trường có hiệu lực. 3. Tối ưu SEO cho Next.js (Search Engine Optimization) Với một ứng dụng hướng tới người dùng (B2C) như xem bói Tarot, việc xuất hiện trên Google là sống còn. Next.js (App Router) hỗ trợ SEO cực mạnh thông qua Metadata API.\nDynamic Metadata: Thay vì chỉ đặt title tĩnh, bạn có thể tạo title động dựa trên lá bài Tarot mà người dùng bốc được:\n// app/tarot/[cardId]/page.tsx export async function generateMetadata({ params }) { const card = await getTarotCard(params.cardId); return { title: `Ý nghĩa lá bài ${card.name} | SorcererXtreme`, description: `Khám phá thông điệp vũ trụ từ lá bài ${card.name}...`, openGraph: { images: [card.imageUrl], // Ảnh hiển thị khi share lên Facebook }, } } 4. Giám sát \u0026amp; Phân tích (Monitoring \u0026amp; Analytics) Bạn không thể cải thiện những gì bạn không đo lường. Sử dụng Tab Monitoring trong Amplify để theo dõi:\nIncoming Traffic: Số lượng người truy cập theo thời gian thực. Data Transfer: Dung lượng băng thông đã sử dụng. Error Rate (4XX/5XX): Phát hiện ngay nếu API bị lỗi hoặc link hỏng. Access Logs: Tải xuống log truy cập để phân tích hành vi người dùng (họ đến từ quốc gia nào, dùng trình duyệt gì). Front-end Tip: Luôn kiểm tra điểm số Lighthouse (trong Chrome DevTools) sau mỗi lần deploy. Một ứng dụng đẹp nhưng load chậm sẽ khiến người dùng rời bỏ ngay lập tức. Hãy tối ưu ảnh (dùng format WebP/AVIF) và lazy-load các component nặng.\n"
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.3-backend-development/2.3.5-cicd/",
	"title": "Tự động hóa CI/CD",
	"tags": [],
	"description": "",
	"content": "Mục tiêu của phần này là thiết lập quy trình để mỗi khi code được đẩy lên nhánh main, toàn bộ kiến trúc Serverless của bạn sẽ được tự động Build, Test, và Deploy lên AWS mà không cần thao tác thủ công từ máy cá nhân.\n1. Chuẩn bị Secret trên GitHub Repo Đây là bước quan trọng nhất để cấp quyền cho GitHub Actions truy cập vào AWS.\nSecret Name Vai trò Ghi chú và Thao tác AWS_ACCESS_KEY_ID Key truy cập AWS. RẤT QUAN TRỌNG: Sử dụng IAM User có quyền hạn tối thiểu (không phải Admin) để chỉ có thể tạo/cập nhật các tài nguyên Lambda, API Gateway, và đọc SSM. AWS_SECRET_ACCESS_KEY Secret Key tương ứng. (Giữ nguyên) SERVERLESS_ACCESS_KEY Key Serverless Dashboard. Chỉ cần thiết nếu bạn sử dụng các tính năng quản lý của Serverless Dashboard. Nếu không, có thể bỏ qua. 2. File Workflow .github/workflows/deploy.yml File này định nghĩa các bước mà GitHub Actions sẽ thực hiện. Chúng ta sẽ thêm bước Build và loại bỏ các biến môi trường không cần thiết cho lệnh deploy.\nname: Deploy Backend CI/CD via Serverless Framework on: push: branches: [ main ] # Kích hoạt khi push lên nhánh main workflow_dispatch: # Kích hoạt thủ công từ GitHub UI jobs: deploy: runs-on: ubuntu-latest # Cấp quyền cho GitHub Actions permissions: id-token: write contents: read steps: - uses: actions/checkout@v4 # 1. Lấy mã nguồn - name: Setup Node 20 uses: actions/setup-node@v3 with: node-version: \u0026#39;20\u0026#39; cache: \u0026#39;npm\u0026#39; # Kích hoạt cache để tăng tốc cài đặt - name: Install Dependencies run: npm ci # Dùng npm ci để đảm bảo tính nhất quán (từ package-lock.json) # --- CẤU HÌNH PRISMA \u0026amp; BUILD CODE --- - name: Generate Prisma Client (tải binary Linux) # Tải binary rhel-openssl-3.0.x (cần thiết cho Lambda) run: npx prisma generate - name: Build TypeScript Code (tsc -\u0026gt; dist) # Chạy lệnh biên dịch (giả định script \u0026#34;build\u0026#34;: \u0026#34;tsc\u0026#34; có trong package.json) run: npm run build # --- CẤU HÌNH AWS --- - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v4 with: aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} aws-region: ap-southeast-1 # --- TRIỂN KHAI CUỐI CÙNG --- - name: Deploy Serverless # Dùng npx để gọi serverless CLI run: npx serverless deploy env: # Chỉ định rõ stage triển khai. SLS_STAGE: dev # [Lưu ý]: Biến DATABASE_URL đã được xử lý bằng placeholder hoặc SSM DATABASE_URL: \u0026#34;placeholder\u0026#34; 3. Quy trình CI/CD Code Commit: Bạn phát triển code và thực hiện git push lên GitHub. Kích hoạt: GitHub Actions tự động kích hoạt workflow deploy.yml. Build \u0026amp; Package: Runner Ubuntu cài đặt dependencies, chạy npx prisma generate (tải binary Linux), và biên dịch code. AWS Authentication: aws-actions/configure-aws-credentials đăng nhập vào AWS bằng Secret Key của bạn. Provisioning: Lệnh npx serverless deploy đọc serverless.yml, kết nối SSM Parameter Store để lấy các Key bí mật, và ra lệnh cho CloudFormation xây dựng/cập nhật toàn bộ hạ tầng Lambda và API Gateway. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.4-ai-development/2.4.6-roadmap/",
	"title": "Bài học &amp; Lộ trình",
	"tags": [],
	"description": "",
	"content": "1. Những thách thức kỹ thuật \u0026amp; Bài học xương máu Quá trình xây dựng hệ thống AI tư vấn huyền học không chỉ là việc ghép nối các dịch vụ AWS lại với nhau, mà là cuộc chiến về Chất lượng dữ liệu và Ngữ nghĩa.\nVấn đề Nhiễu thông tin (RAG Hallucination): Thực tế: Dữ liệu huyền học thường trừu tượng. Khi User hỏi một câu mơ hồ (ví dụ: \u0026ldquo;Tương lai tôi thế nào?\u0026rdquo;), Vector Search dễ trả về các kết quả không liên quan (Noise), khiến LLM \u0026ldquo;ảo giác\u0026rdquo; bịa ra câu trả lời. Bài học: Chất lượng của bộ dữ liệu (Knowledge Base) quan trọng hơn số lượng. Việc chia nhỏ (Chunking) dữ liệu theo cấu trúc .jsonl và gắn thẻ Metadata kỹ lưỡng là chìa khóa để tăng độ chính xác (Precision). Thách thức Ngôn ngữ (Vietnamese Nuance): Thực tế: Các model Embedding quốc tế đôi khi không hiểu hết các thuật ngữ Hán-Việt trong Tử vi (ví dụ: \u0026ldquo;Cung Mệnh\u0026rdquo;, \u0026ldquo;Thiên Di\u0026rdquo;). Giải pháp: Phải sử dụng model cohere.embed-multilingual-v3 và kỹ thuật Hybrid Search (kết hợp tìm kiếm từ khóa chính xác của DynamoDB và tìm kiếm ngữ nghĩa của Pinecone) để bù đắp khiếm khuyết này. 2. Hướng phát triển Mục tiêu tiếp theo không chỉ là AI trả lời đúng, mà là trả lời \u0026ldquo;đúng cho riêng BẠN\u0026rdquo;. Hệ thống sẽ chuyển dịch từ tư vấn chung chung sang tư vấn định danh.\nCơ chế phản hồi người dùng (Feedback Loop - RLHF Lite) Xây dựng cơ chế Like/Dislike cho từng câu trả lời. Dữ liệu này sẽ được lưu lại để:\nTinh chỉnh lại Prompt (Prompt Tuning). Lọc bỏ các đoạn dữ liệu RAG kém chất lượng ra khỏi Pinecone. 3. Lời kết Hệ thống hiện tại đã thiết lập được một nền móng vững chắc: Serverless để tối ưu chi phí, Pinecone để xử lý trí nhớ, và Python để kết nối vạn vật.\nViệc chuyển hướng sang Cá nhân hóa sẽ là bước nhảy vọt, biến hệ thống từ một công cụ \u0026ldquo;Tra cứu thông tin\u0026rdquo; (Search Engine) thành một \u0026ldquo;Trợ lý tâm linh\u0026rdquo; (Spiritual Companion) thực thụ, có khả năng thấu hiểu và đồng hành sâu sắc với người dùng.\n"
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.3-backend-development/2.3.6-microservice/",
	"title": "Kết nối microservices",
	"tags": [],
	"description": "",
	"content": "Gọi API Nội bộ (Backend -\u0026gt; AI Service) Trong kiến trúc Serverless, khi một hàm Lambda (ví dụ: Chatbot) cần gọi một dịch vụ khác (MetaphysicalAPI), phương pháp tốt nhất là sử dụng HTTP request thông qua API Gateway của dịch vụ đó.\n1. Nguyên tắc Gọi API Endpoint: Luôn gọi thông qua API Gateway Endpoint công khai (hoặc nội bộ nếu cả hai Lambda đều trong VPC và dùng Private API Gateway). Thư viện: Sử dụng thư viện HTTP quen thuộc như axios để quản lý yêu cầu và timeout phía client. Bảo mật: Sử dụng IAM Roles hoặc API Keys để xác thực cuộc gọi giữa các dịch vụ nếu API Gateway không hoàn toàn công khai. 2. Quản lý Thời gian chờ (Timeout) Quản lý timeout là yếu tố quan trọng nhất để tránh lỗi 504 Gateway Timeout.\nAPI Gateway Limit: API Gateway có giới hạn thời gian chờ cứng là 29 giây. Mọi request kéo dài hơn 29 giây đều bị cắt và trả về lỗi 504. Lambda Limit: Lambda có thể chạy tới 15 phút, nhưng bị giới hạn bởi API Gateway. Do đó, thời gian chờ của Lambda phải được đặt nhỏ hơn 29 giây (ví dụ: 25 giây). Cấu hình Vị trí Giá trị Khuyến nghị Lý do Timeout API Gateway serverless.yml (Provider level) 29 giây Giới hạn tối đa của AWS. Timeout Lambda (Receiver) serverless.yml (Function level) 25 giây Phải nhỏ hơn 29s để Lambda kịp trả lỗi trước khi API Gateway cắt. Timeout Client (axios) Code TypeScript 25,000 ms (25 giây) Đảm bảo client cắt kết nối trước khi Lambda hết thời gian chờ, cho phép xử lý lỗi phía client gọn gàng. 3. Tối ưu Hiệu suất Lambda Nếu AI Service của bạn thực hiện các tác vụ nặng (như RAG, tính toán thiên văn), việc tối ưu tốc độ xử lý là bắt buộc.\nTăng Bộ nhớ (RAM): Tăng memorySize của AI Service Lambda lên mức cao (ví dụ: 1536 MB hoặc 3008 MB). Trên AWS, tăng RAM cũng đồng thời tăng CPU và Network Bandwidth, giúp xử lý nặng nhanh hơn đáng kể, giảm khả năng xảy ra lỗi 504. Cấu hình Code: Cấu hình timeout: 25 trong serverless.yml cho cả Backend và AI Service. 4. Code mẫu Đây là hàm gọi AI đã được chỉnh sửa để xử lý các ngoại lệ một cách rõ ràng và tuân thủ nguyên tắc Timeout.\nimport axios from \u0026#39;axios\u0026#39;; // Giả định AI_SERVICE_URL đã được lấy từ AWS SSM Parameter Store và bơm vào ENV const AI_SERVICE_URL = process.env.AI_SERVICE_URL; const CLIENT_TIMEOUT_MS = 25000; // 25 giây (Dưới giới hạn 29s của API Gateway) /** * Gọi API Gateway của dịch vụ AI để nhận phản hồi. * @param prompt Dữ liệu yêu cầu gửi đến AI. */ export const callAI = async (prompt: string, userId: string) =\u0026gt; { if (!AI_SERVICE_URL) { throw new Error(\u0026#34;AI Service URL is not configured.\u0026#34;); } try { const res = await axios.post(AI_SERVICE_URL, { prompt, userId // Gửi ID người dùng để AI Service có thể log hoặc xử lý VIP }, { timeout: CLIENT_TIMEOUT_MS // Thiết lập timeout client }); // Xử lý response thành công return res.data; } catch (error) { if (axios.isAxiosError(error) \u0026amp;\u0026amp; error.code === \u0026#39;ECONNABORTED\u0026#39;) { // Lỗi Timeout phía client console.error(\u0026#34;AI Timeout Error: Request took too long.\u0026#34;); throw new Error(\u0026#34;AI Service timed out (504). Please try again.\u0026#34;); } // Lỗi khác (ví dụ: 4xx, 5xx từ AI Service) console.error(\u0026#34;AI Service Error:\u0026#34;, error.message); throw new Error(\u0026#34;AI Service unavailable or returned an error.\u0026#34;); } }; "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.2-frontend-development/2.2.6-backend-architecture/",
	"title": "Kiến trúc Backend tham khảo (RAG &amp; Database)",
	"tags": [],
	"description": "",
	"content": "Là một Frontend Developer hiện đại, ranh giới giữa Frontend và Backend ngày càng mờ nhạt. Bạn không cần phải viết code SQL hay quản lý server, nhưng bạn bắt buộc phải hiểu luồng dữ liệu để tích hợp hiệu quả.\nHệ thống SorcererXtreme sử dụng kiến trúc RAG (Retrieval-Augmented Generation) tiên tiến. Hãy cùng mổ xẻ xem điều gì xảy ra sau khi bạn gọi fetch('/api/chat').\n1. RAG Flow: Tại sao AI trả lời chính xác? Nếu chỉ đơn thuần gửi câu hỏi cho ChatGPT, nó sẽ \u0026ldquo;chém gió\u0026rdquo; dựa trên dữ liệu cũ. Để AI đóng vai một \u0026ldquo;Phù thủy thông thái\u0026rdquo; am hiểu Tarot, chúng ta dùng quy trình 4 bước:\nRetrieval (Truy tìm): Khi User hỏi \u0026ldquo;Lá bài The Fool có ý nghĩa gì?\u0026rdquo;, câu hỏi được chuyển thành vector (dạng số). Hệ thống tìm trong Pinecone (Vector DB) những đoạn văn bản trong sách Tarot có ý nghĩa tương đồng nhất. Augmentation (Tăng cường): Hệ thống ghép câu hỏi gốc + nội dung tìm được từ Pinecone thành một Prompt hoàn chỉnh. Prompt: \u0026ldquo;Dựa vào kiến thức sau [trích đoạn sách\u0026hellip;], hãy trả lời câu hỏi: Lá bài The Fool có ý nghĩa gì?\u0026rdquo; Generation (Tạo sinh): Gửi Prompt này đến Amazon Bedrock (chứa model Claude 3 hoặc Titan). AI sẽ trả lời dựa trên chính xác những gì sách viết, tránh bịa đặt. Response: Frontend nhận câu trả lời cuối cùng và hiển thị. 2. Chiến lược \u0026ldquo;Đa cơ sở dữ liệu\u0026rdquo; (Polyglot Persistence) Một ứng dụng lớn không bao giờ chỉ dùng một loại Database. Chúng ta dùng đúng công cụ cho đúng việc:\nA. NeonDB (Serverless PostgreSQL)\nLoại: Quan hệ (Relational). Dữ liệu: User Profile, Thông tin gói VIP, Giao dịch thanh toán. Tại sao: Dữ liệu tiền bạc cần tính toàn vẹn (ACID) cao nhất. SQL là lựa chọn số 1. B. Amazon DynamoDB\nLoại: NoSQL (Key-Value). Dữ liệu: Lịch sử Chat, Logs hoạt động. Tại sao: Chat sinh ra hàng triệu bản ghi. DynamoDB có thể ghi/đọc cực nhanh với độ trễ thấp (single-digit millisecond) bất kể data lớn cỡ nào. C. Pinecone\nLoại: Vector Database. Dữ liệu: Kiến thức Tarot, Chiêm tinh (đã được mã hóa thành Vector). Tại sao: SQL hay NoSQL không thể tìm kiếm theo \u0026ldquo;ngữ nghĩa\u0026rdquo; (semantic search). Chỉ Vector DB mới hiểu rằng \u0026ldquo;Vua tiền\u0026rdquo; và \u0026ldquo;King of Pentacles\u0026rdquo; là liên quan nhau. 3. Bảo mật: Mô hình \u0026ldquo;Pháo đài\u0026rdquo; (Fortress) Frontend của bạn (sorcererxtreme.vn) là vùng đất công cộng ai cũng vào được. Nhưng Backend là \u0026ldquo;thánh địa\u0026rdquo;.\nKhông lộ diện Database: NeonDB hay Pinecone không bao giờ mở cổng ra Internet. API Gateway là lính gác: Mọi yêu cầu phải đi qua API Gateway. Nó kiểm tra \u0026ldquo;thẻ bài\u0026rdquo; (Cognito Token). Nếu không có hoặc hết hạn -\u0026gt; Chặn ngay lập tức (401 Unauthorized). Lambda là người vận chuyển: Chỉ có Lambda function (nằm trong vùng mạng riêng VPC) mới có chìa khóa (Secret Key) để mở cửa vào Database. Takeaway: Khi debug lỗi \u0026ldquo;tại sao AI trả lời sai?\u0026rdquo;, Frontend Dev có thể đoán ngay: \u0026ldquo;À, có thể bước Retrieval ở Pinecone tìm sai context\u0026rdquo;, thay vì đổ lỗi ngay cho Model AI. Hiểu hệ thống giúp bạn fix bug nhanh hơn!\n"
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.2-frontend-development/2.2.7-cleanup/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Sau khi hoàn thành Workshop, việc dọn dẹp là bắt buộc để tránh phát sinh chi phí \u0026ldquo;oan\u0026rdquo; từ AWS. Vì chúng ta sử dụng Services Serverless (Amplify, Lambda, Bedrock), việc dọn dẹp khá đơn giản nhưng cần kỹ lưỡng.\n1. Xóa ứng dụng trên AWS Amplify Đây là bước quan trọng nhất. Xóa App trên Amplify sẽ tự động dọn dẹp 80% tài nguyên liên quan (Hosting S3, CloudFront, CI/CD Pipeline).\nTruy cập AWS Amplify Console. Chọn ứng dụng SorcererXtreme. Vào tab Actions (góc trên bên phải) -\u0026gt; Chọn Delete app. Nhập cụm từ xác nhận (thường là delete) và nhấn Confirm. 2. Dọn dẹp Database \u0026amp; External Services Vì NeonDB và Pinecone là dịch vụ bên thứ 3 (không nằm trong gói Amplify Delete), bạn cần xóa thủ công:\nNeonDB: Đăng nhập Console Neon. Vào Settings của Project -\u0026gt; Delete Project. Pinecone: Đăng nhập Console Pinecone. Xóa Index (ví dụ tarot-knowledge-base) để dừng tính phí lưu trữ vector. 3. Dọn dẹp tài nguyên AWS thủ công (Nếu có tạo lẻ) Nếu trong quá trình làm bạn có tạo thêm tài nguyên ngoài Amplify, hãy kiểm tra:\nAmazon Bedrock: Bedrock tính tiền theo Request (On-demand) nên không cần xóa \u0026ldquo;Model\u0026rdquo;. Tuy nhiên nếu bạn có tạo Knowledge Base riêng, hãy xóa nó. Amazon Cognito: Kiểm tra xem User Pool đã mất chưa (thường Amplify xóa giúp rồi). Parameter Store: Vào AWS Systems Manager \u0026gt; Parameter Store \u0026gt; Xóa các key như /sorcerer/neon_db_url, /sorcerer/pinecone_api_key. 4. Kiểm tra lần cuối (Billing Dashboard) Để chắc chắn 100%:\nTruy cập AWS Billing Dashboard. Kiểm tra mục \u0026ldquo;Bills\u0026rdquo;. Đợi 24h để hệ thống cập nhật và đảm bảo không có chi phí mới phát sinh từ các dịch vụ lạ. Lời kết Chúc mừng bạn đã đi đến cuối hành trình!\nBạn đã hoàn thành việc xây dựng SorcererXtreme - một ứng dụng kết hợp giữa nghệ thuật Frontend (Next.js), sức mạnh Cloud (AWS Amplify) và trí tuệ nhân tạo (Bedrock RAG).\nHẹn gặp lại bạn ở các Workshop nâng cao!\n"
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.3-backend-development/2.3.7-email/",
	"title": "Thiết lập Email",
	"tags": [],
	"description": "",
	"content": "Để đảm bảo email của dự án được gửi đi với độ tin cậy cao nhất và tránh bị các nhà cung cấp dịch vụ email (như Gmail, Outlook) đánh dấu là Spam, việc cấu hình bảo mật tên miền là bắt buộc.\n1. Cấu hình Cơ bản và Bảo mật Danh tính Bước Hoạt động Mục đích 1. Mua Domain Sử dụng domain riêng (.com, .xyz) thay vì domain dùng chung. Uy tín: Xây dựng danh tiếng gửi email riêng biệt, tránh bị ảnh hưởng bởi người gửi xấu khác. 2. Verify Domain trong AWS SES Truy cập SES -\u0026gt; Verified Identities -\u0026gt; Create Identity (Chọn Domain). Chứng minh Quyền sở hữu: Cho phép AWS SES quản lý việc gửi email thay mặt cho tên miền của bạn. 3. Cấu hình DNS (Bảo mật Email) Thêm các bản ghi CNAME (DKIM), TXT (SPF), và TXT (DMARC). Quan trọng: Các bản ghi này xác minh nguồn gửi (DKIM/SPF) và hướng dẫn máy chủ nhận xử lý email không hợp lệ (DMARC), ngăn chặn email rơi vào Spam. Chi tiết các Bản ghi DNS bắt buộc: DKIM (CNAME): Thêm 3 bản ghi CNAME mà AWS SES cung cấp. Mục đích: Chữ ký số. SPF (TXT): Thêm bản ghi TXT với nội dung: v=spf1 include:amazonses.com ~all. Mục đích: Xác định AWS SES là máy chủ được ủy quyền để gửi mail. DMARC (TXT): Thêm bản ghi TXT (thường dưới dạng _dmarc) với nội dung: v=DMARC1; p=none;. Mục đích: Thiết lập chính sách báo cáo và xử lý email giả mạo. 2. Thiết lập Luồng Gửi và Vượt Sandbox Sau khi tên miền đã được xác minh (Verification Status: Verified), bạn cần thiết lập luồng vận hành và xin quyền gửi thực tế.\nBước Dịch vụ tương tác Hoạt động 1. Kích hoạt Luồng Async EventBridge Scheduler -\u0026gt; Lambda (TriggerReminder) Luồng bất đồng bộ bắt đầu theo lịch trình đã định. 2. Gửi Yêu cầu SES Lambda (TriggerReminder) -\u0026gt; Amazon SES API Hàm Lambda (đã được cấp quyền IAM Role) gọi trực tiếp SES API (ví dụ: SendEmailCommand) để gửi email cá nhân hóa cho từng người dùng. 3. Request Production Access AWS Support Center Gửi ticket yêu cầu AWS nâng cấp tài khoản của bạn khỏi chế độ Sandbox để bạn có thể gửi email đến bất kỳ địa chỉ nào chưa được xác minh. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/2-workshop/2.3-backend-development/2.3.8-summary/",
	"title": "Tổng kết quy trình làm việc",
	"tags": [],
	"description": "",
	"content": "Quy trình làm việc được thiết kế để tận dụng tốc độ phát triển cục bộ và tính an toàn, tự động của kiến trúc Serverless.\nBước Hoạt động Môi trường Vai trò và Ghi chú 1. Phát triển Code Code logic, sửa đổi API (TypeScript/Express). Máy Local Sử dụng VS Code và các thư viện Node.js. 2. Kiểm thử Cục bộ Test đồng bộ API. sls offline start Giả lập môi trường Lambda/API Gateway. Kết nối trực tiếp với NeonDB qua file .env local. 3. Cập nhật Schema DB Nếu sửa đổi Schema (schema.prisma). npx prisma migrate dev Tạo Migration và áp dụng các thay đổi. 4. Commit \u0026amp; Đẩy Code Commit code và đẩy lên kho chứa. git push origin main Kích hoạt luồng tự động hóa CI/CD. 5. CI/CD Tự động Triển khai lên Cloud. GitHub Actions Tự động: Build -\u0026gt; Prisma Generate -\u0026gt; Đăng nhập AWS/SSM (lấy Key) -\u0026gt; Deplo lên AWS Lambda. 6. Giám sát Lỗi Kiểm tra Log thời gian thực. sls logs -f api -t Dùng lệnh Serverless Framework để xem CloudWatch Logs ngay lập tức và debug lỗi trong môi trường Production/Staging. Ghi chú Quan trọng về Prisma: Dùng migrate dev: Thay vì db push (chỉ dùng cho non-production/test), bạn nên dùng npx prisma migrate dev để tạo lịch sử thay đổi (migration files) và áp dụng lên NeonDB. Generate trên CI/CD: Việc chạy npx prisma generate trong GitHub Actions là bắt buộc để tải xuống các binaries (rhel-openssl-3.0.x) cần thiết cho môi trường Linux của AWS Lambda. "
},
{
	"uri": "http://localhost:1313/repo-name/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/repo-name/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]